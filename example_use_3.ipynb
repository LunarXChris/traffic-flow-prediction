{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "example_use_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c9d73bb-e8d5-4aeb-a928-93db9ac6241c"
      },
      "source": [
        "# Transformer boilerplate code + how to use it\n",
        "##### by Daniel Melchor (dmh672@gmail.com)"
      ],
      "id": "2c9d73bb-e8d5-4aeb-a928-93db9ac6241c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31985af0-d58e-4d01-8432-065537022502"
      },
      "source": [
        "---\n",
        "## Imports"
      ],
      "id": "31985af0-d58e-4d01-8432-065537022502"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "446258e5-7cf2-4a73-8dd7-7b7a43fdd98e",
        "outputId": "a6479a0a-ad21-46a5-e07b-daecdd8996c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install torch numpy matplotlib"
      ],
      "id": "446258e5-7cf2-4a73-8dd7-7b7a43fdd98e",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3539f61f-fe7d-4428-b074-327a883f7f6e"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "3539f61f-fe7d-4428-b074-327a883f7f6e",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c72c2ada-2106-4505-82f5-086e518080a5",
        "tags": []
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, dim_model, dropout_p, max_len):\n",
        "        super().__init__()\n",
        "        # Modified version from: https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
        "        # max_len determines how far the position can have an effect on a token (window)\n",
        "        \n",
        "        # Info\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        \n",
        "        # Encoding - From formula\n",
        "        pos_encoding = torch.zeros(max_len, dim_model)\n",
        "        positions_list = torch.arange(0, max_len, dtype=torch.float).view(-1, 1) # 0, 1, 2, 3, 4, 5\n",
        "        division_term = torch.exp(torch.arange(0, dim_model, 2).float() * (-math.log(10000.0)) / dim_model) # 1000^(2i/dim_model)\n",
        "        \n",
        "        # PE(pos, 2i) = sin(pos/1000^(2i/dim_model))\n",
        "        pos_encoding[:, 0::2] = torch.sin(positions_list * division_term)\n",
        "        \n",
        "        # PE(pos, 2i + 1) = cos(pos/1000^(2i/dim_model))\n",
        "        pos_encoding[:, 1::2] = torch.cos(positions_list * division_term)\n",
        "        \n",
        "        # Saving buffer (same as parameter without gradients needed)\n",
        "        pos_encoding = pos_encoding.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pos_encoding\",pos_encoding)\n",
        "        \n",
        "    def forward(self, token_embedding: torch.tensor) -> torch.tensor:\n",
        "        # Residual connection + pos encoding\n",
        "        return self.dropout(token_embedding + self.pos_encoding[:token_embedding.size(0), :])"
      ],
      "id": "c72c2ada-2106-4505-82f5-086e518080a5",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "588b2729-866c-470a-aca7-6a3c5ea0b192",
        "tags": []
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Model from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
        "    Daniel Melchor: https://medium.com/p/c80afbc9ffb1/\n",
        "    \"\"\"\n",
        "    # Constructor\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_tokens,\n",
        "        dim_model,\n",
        "        num_heads,\n",
        "        num_encoder_layers,\n",
        "        num_decoder_layers,\n",
        "        dropout_p,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # INFO\n",
        "        self.model_type = \"Transformer\"\n",
        "        self.dim_model = dim_model\n",
        "\n",
        "        # LAYERS\n",
        "        self.positional_encoder = PositionalEncoding(\n",
        "            dim_model=dim_model, dropout_p=dropout_p, max_len=5000\n",
        "        )\n",
        "        self.embedding = nn.Embedding(num_tokens, dim_model)\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=dim_model,\n",
        "            nhead=num_heads,\n",
        "            num_encoder_layers=num_encoder_layers,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            dropout=dropout_p,\n",
        "        )\n",
        "        self.out = nn.Linear(dim_model, num_tokens)\n",
        "        \n",
        "    def forward(self, src, tgt, tgt_mask=None, src_pad_mask=None, tgt_pad_mask=None):\n",
        "        # Src size must be (batch_size, src sequence length)\n",
        "        # Tgt size must be (batch_size, tgt sequence length)\n",
        "\n",
        "        # Embedding + positional encoding - Out size = (batch_size, sequence length, dim_model)\n",
        "        src = self.embedding(src) * math.sqrt(self.dim_model)\n",
        "        tgt = self.embedding(tgt) * math.sqrt(self.dim_model)\n",
        "        src = self.positional_encoder(src)\n",
        "        tgt = self.positional_encoder(tgt)\n",
        "        \n",
        "        # We could use the parameter batch_first=True, but our KDL version doesn't support it yet, so we permute\n",
        "        # to obtain size (sequence length, batch_size, dim_model),\n",
        "        src = src.permute(1,0,2)\n",
        "        tgt = tgt.permute(1,0,2)\n",
        "\n",
        "        # Transformer blocks - Out size = (sequence length, batch_size, num_tokens)\n",
        "        transformer_out = self.transformer(src, tgt, tgt_mask=tgt_mask, src_key_padding_mask=src_pad_mask, tgt_key_padding_mask=tgt_pad_mask)\n",
        "        out = self.out(transformer_out)\n",
        "        \n",
        "        return out\n",
        "      \n",
        "    def get_tgt_mask(self, size) -> torch.tensor:\n",
        "        # Generates a squeare matrix where the each row allows one word more to be seen\n",
        "        mask = torch.tril(torch.ones(size, size) == 1) # Lower triangular matrix\n",
        "        mask = mask.float()\n",
        "        mask = mask.masked_fill(mask == 0, float('-inf')) # Convert zeros to -inf\n",
        "        mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n",
        "        \n",
        "        # EX for size=5:\n",
        "        # [[0., -inf, -inf, -inf, -inf],\n",
        "        #  [0.,   0., -inf, -inf, -inf],\n",
        "        #  [0.,   0.,   0., -inf, -inf],\n",
        "        #  [0.,   0.,   0.,   0., -inf],\n",
        "        #  [0.,   0.,   0.,   0.,   0.]]\n",
        "        \n",
        "        return mask\n",
        "    \n",
        "    def create_pad_mask(self, matrix: torch.tensor, pad_token: int) -> torch.tensor:\n",
        "        # If matrix = [1,2,3,0,0,0] where pad_token=0, the result mask is\n",
        "        # [False, False, False, True, True, True]\n",
        "        return (matrix == pad_token)"
      ],
      "id": "588b2729-866c-470a-aca7-6a3c5ea0b192",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the dataset for training and validation# Notice,we need to put SOS and EOS into the dataset; Compared with seq2se1 Code"
      ],
      "metadata": {
        "id": "vOKijoZX662r"
      },
      "id": "vOKijoZX662r"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AcH-m0J6_OD",
        "outputId": "c1b7e428-3af1-4284-ffe7-fb4eb84b5ca3"
      },
      "id": "_AcH-m0J6_OD",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fp = open('/content/drive/My Drive/project/i580w_jan 2012_input.txt','r')\n",
        "input_data=[]\n",
        "for line in fp:\n",
        "    line=line.strip('\\n')   #将\\n去掉\n",
        "    input_data.append(line.split(' '))   #将空格作为分隔符将一个字符切割成一个字符数组\n",
        "\n",
        "fp.close()\n",
        "input_data=np.array(input_data,dtype=int)   #将其转换成numpy的数组，并定义数据类型为float\n",
        "\n",
        "fp = open('/content/drive/My Drive/project/i580w_jan 2012_target.txt','r')\n",
        "target_data=[]\n",
        "for line in fp:\n",
        "    line=line.strip('\\n')   #将\\n去掉\n",
        "    target_data.append(line.split(' '))   #将空格作为分隔符将一个字符切割成一个字符数组\n",
        "\n",
        "fp.close()\n",
        "target_data=np.array(target_data,dtype=int)   #将其转换成numpy的数组，并定义数据类型为float\n",
        "#input_data = np.delete(input_data,[3,11,19],axis = 1) #delete the null column\n",
        "#target_data = np.delete(target_data,[3],axis = 1)\n",
        "#input_data = input_data[:,16:]\n",
        "print(\"input data shape:\",input_data.shape)\n",
        "print(\"target data shape:\",target_data.shape)\n",
        "print(input_data[:8])\n",
        "print(target_data[:8])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaZ_IC6Z7dV6",
        "outputId": "129de027-f2c1-4d41-f238-1be9b14e80a3"
      },
      "id": "YaZ_IC6Z7dV6",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input data shape: (8925, 24)\n",
            "target data shape: (8925, 8)\n",
            "[[ 3 12  4  0  0  4  1  2  1  4  1  0  1  6  1  8  2  5  6  0  5  2  1  5]\n",
            " [ 1  4  1  0  1  6  1  8  2  5  6  0  5  2  1  5  2  6  6  0  4  4  0  9]\n",
            " [ 2  5  6  0  5  2  1  5  2  6  6  0  4  4  0  9  4  8 12  0  6  2  0 12]\n",
            " [ 2  6  6  0  4  4  0  9  4  8 12  0  6  2  0 12 11 11 10  0  2  4  2  9]\n",
            " [ 4  8 12  0  6  2  0 12 11 11 10  0  2  4  2  9 15  7 14  0  8  4  0  9]\n",
            " [11 11 10  0  2  4  2  9 15  7 14  0  8  4  0  9 13  7 13  0  4 12  2  9]\n",
            " [15  7 14  0  8  4  0  9 13  7 13  0  4 12  2  9  7 14 14  0  6  3  1 12]\n",
            " [13  7 13  0  4 12  2  9  7 14 14  0  6  3  1 12  9 11 24  0  6  1  3 11]]\n",
            "[[ 2  6  6  0  4  4  0  9]\n",
            " [ 4  8 12  0  6  2  0 12]\n",
            " [11 11 10  0  2  4  2  9]\n",
            " [15  7 14  0  8  4  0  9]\n",
            " [13  7 13  0  4 12  2  9]\n",
            " [ 7 14 14  0  6  3  1 12]\n",
            " [ 9 11 24  0  6  1  3 11]\n",
            " [13 11 23  0  5  6  1 20]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_max = np.max(input_data, axis = 0)\n",
        "input_min = np.min(input_data, axis = 0)\n",
        "output_max = np.max(target_data, axis = 0)\n",
        "output_min = np.min(target_data, axis = 0)\n",
        "\n",
        "print(\"input max:{0},\\n input min:{1},\\n output max:{2},\\n output min:{3}\".format(input_max,input_min,output_max,output_min)) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHEGKszw8Tm7",
        "outputId": "b18add1d-a882-4019-bdd6-8aeda4d882e8"
      },
      "id": "rHEGKszw8Tm7",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input max:[ 91 131 111   0  36  82  33 147  91 131 111   0  36  82  33 147  91 131\n",
            " 111   0  36  82  33 147],\n",
            " input min:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0],\n",
            " output max:[ 91 131 111   0  36  82  33 147],\n",
            " output min:[0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add SOS and EOS"
      ],
      "metadata": {
        "id": "XsBAUzACIwKT"
      },
      "id": "XsBAUzACIwKT"
    },
    {
      "cell_type": "code",
      "source": [
        "def addsoseos(X):\n",
        "  SOS = np.ones([X.shape[0],1])*(150)\n",
        "  EOS = np.ones([X.shape[0],1])*(152)\n",
        "  X = np.c_[X,EOS]\n",
        "  X = np.c_[SOS,X]\n",
        "  return X"
      ],
      "metadata": {
        "id": "3efdHVfHIwuM"
      },
      "id": "3efdHVfHIwuM",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalization(data):\n",
        "    _range = np.max(data) - np.min(data)\n",
        "    return (data - np.min(data)) / _range\n",
        " \n",
        "\n",
        "def standardization(data):\n",
        "    mu = np.mean(data, axis=0)\n",
        "    sigma = np.std(data, axis=0)\n",
        "    return (data - mu) / sigma"
      ],
      "metadata": {
        "id": "PZs4tRfY-YT7"
      },
      "id": "PZs4tRfY-YT7",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_data = normalization(input_data) \n",
        "# target_data = normalization(target_data)\n",
        "# print(input_data[:8])\n",
        "# print(target_data[:8])"
      ],
      "metadata": {
        "id": "2lvKWcGK-bhx"
      },
      "id": "2lvKWcGK-bhx",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = addsoseos(input_data)\n",
        "target_data = addsoseos(target_data)"
      ],
      "metadata": {
        "id": "TMekALw9L53i"
      },
      "id": "TMekALw9L53i",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import torch.utils.data as Data\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(input_data, target_data, test_size=0.2, random_state = 42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1)"
      ],
      "metadata": {
        "id": "rO3OQGw6BgtT"
      },
      "id": "rO3OQGw6BgtT",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-j2831tBjUC",
        "outputId": "3b7bcae1-b840-4243-b2a4-63e547067ba7"
      },
      "id": "8-j2831tBjUC",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6426, 26)\n",
            "(6426, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Batch_Size = 16\n",
        "train_dataset = Data.TensorDataset(torch.from_numpy(X_train),torch.from_numpy(y_train))\n",
        "\n",
        "#load training data\n",
        "train_dataloader = Data.DataLoader(dataset = train_dataset,\n",
        "                 batch_size = Batch_Size,\n",
        "                 shuffle = True)\n",
        "\n",
        "val_dataset = Data.TensorDataset(torch.from_numpy(X_val),torch.from_numpy(y_val))\n",
        "#load validation data\n",
        "val_dataloader = Data.DataLoader(dataset = val_dataset,\n",
        "                 batch_size = Batch_Size,\n",
        "                 shuffle = False)\n",
        "\n",
        "test_dataset = Data.TensorDataset(torch.from_numpy(X_test),torch.from_numpy(y_test))\n",
        "#load testing data\n",
        "test_loader = Data.DataLoader(dataset = test_dataset,\n",
        "                 batch_size = Batch_Size,\n",
        "                 shuffle = False)\n"
      ],
      "metadata": {
        "id": "oQ3g-yMbFArb"
      },
      "id": "oQ3g-yMbFArb",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add SOS and EOS\n",
        "# def generate_smaple(X,y):#X:6426*21; y:6426*7\n",
        "#   data = []\n",
        "#   SOS_token = np.array([2])#start of token\n",
        "#   EOS_token = np.array([3])#start of token\n",
        "#   for i in range(X.shape[0]):\n",
        "#     data_X = np.concatenate((SOS_token, X[i].ravel(), EOS_token))\n",
        "#     data_y = np.concatenate((SOS_token, y[i].ravel(), EOS_token))\n",
        "#     data.append([data_X, data_y])\n",
        "#   np.random.shuffle(data)\n",
        "#   return data"
      ],
      "metadata": {
        "id": "gHnv9CQbBuVR"
      },
      "id": "gHnv9CQbBuVR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data = generate_smaple(X_train,y_train)\n",
        "# print(train_data[1])\n",
        "# print(train_data[1][0])\n",
        "# print(train_data[1][1])\n",
        "# print(np.shape(train_data))"
      ],
      "metadata": {
        "id": "1GrkeyetCv4E"
      },
      "id": "1GrkeyetCv4E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ac39c4a-ab17-4487-a1ab-2b107e880574"
      },
      "source": [
        "def generate_random_data(n):\n",
        "    SOS_token = np.array([2])#start of token\n",
        "    EOS_token = np.array([3])#end of token\n",
        "    print(SOS_token)\n",
        "    print(EOS_token)\n",
        "    length = 5\n",
        "\n",
        "    data = []\n",
        "\n",
        "    # 1,1,1,1,1,1 -> 1,1,1,1,1\n",
        "    for i in range(n // 3):\n",
        "        X = np.concatenate((SOS_token, np.ones(length), EOS_token))\n",
        "        y = np.concatenate((SOS_token, np.ones(length), EOS_token))\n",
        "        data.append([X, y])\n",
        "\n",
        "    # 0,0,0,0 -> 0,0,0,0\n",
        "    for i in range(n // 3):\n",
        "        X = np.concatenate((SOS_token, np.zeros(length), EOS_token))\n",
        "        y = np.concatenate((SOS_token, np.zeros(length), EOS_token))\n",
        "        data.append([X, y])\n",
        "\n",
        "    # 1,0,1,0 -> 1,0,1,0,1\n",
        "    for i in range(n // 3):\n",
        "        X = np.zeros(length)\n",
        "        start = random.randint(0, 1)\n",
        "\n",
        "        X[start::2] = 1\n",
        "\n",
        "        y = np.zeros(length)\n",
        "        if X[-1] == 0:\n",
        "            y[::2] = 1\n",
        "        else:\n",
        "            y[1::2] = 1\n",
        "\n",
        "        X = np.concatenate((SOS_token, X, EOS_token))\n",
        "        y = np.concatenate((SOS_token, y, EOS_token))\n",
        "\n",
        "        data.append([X, y])\n",
        "\n",
        "    np.random.shuffle(data)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def batchify_data(data, batch_size=16, padding=False, padding_token=-1):\n",
        "    batches = []\n",
        "    for idx in range(0, len(data), batch_size):\n",
        "        # We make sure we dont get the last bit if its not batch_size size\n",
        "        if idx + batch_size < len(data):\n",
        "            # Here you would need to get the max length of the batch,\n",
        "            # and normalize the length with the PAD token.\n",
        "            if padding:\n",
        "                max_batch_length = 0\n",
        "\n",
        "                # Get longest sentence in batch\n",
        "                for seq in data[idx : idx + batch_size]:\n",
        "                    if len(seq) > max_batch_length:\n",
        "                        max_batch_length = len(seq)\n",
        "\n",
        "                # Append X padding tokens until it reaches the max length\n",
        "                for seq_idx in range(batch_size):\n",
        "                    remaining_length = max_bath_length - len(data[idx + seq_idx])\n",
        "                    data[idx + seq_idx] += [padding_token] * remaining_length\n",
        "\n",
        "            batches.append(np.array(data[idx : idx + batch_size]).astype(np.int64))\n",
        "\n",
        "    print(f\"{len(batches)} batches of size {batch_size}\")\n",
        "\n",
        "    return batches\n",
        "\n",
        "\n",
        "# train_data = generate_random_data(9000)\n",
        "# val_data = generate_random_data(3000)\n",
        "\n",
        "\n",
        "# print(train_data[1][0])\n",
        "# print(train_data[1][1])\n",
        "# print(train_data[3])\n",
        "# print(np.shape(train_data))\n",
        "# train_dataloader = batchify_data(train_data)\n",
        "# val_dataloader = batchify_data(val_data)\n",
        "# print(train_dataloader[1])"
      ],
      "id": "8ac39c4a-ab17-4487-a1ab-2b107e880574",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d04a60a-f013-4eda-b056-fc9bb1b1ea79"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = Transformer(\n",
        "    num_tokens=160, dim_model=8, num_heads=8, num_encoder_layers=4, num_decoder_layers=4, dropout_p=0.1\n",
        ").to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "id": "4d04a60a-f013-4eda-b056-fc9bb1b1ea79",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bc6949f-2d59-44c3-8198-037e115106aa"
      },
      "source": [
        "def train_loop(model, opt, loss_fn, dataloader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    \n",
        "    for batch in dataloader:\n",
        "        #X, y = batch[:, 0], batch[:, 1]\n",
        "        X = batch[0].long()\n",
        "        y = batch[1].long()\n",
        "        #print(X.dtype)\n",
        "        #print(y.dtype)\n",
        "        X, y = torch.tensor(X).to(device), torch.tensor(y).to(device)\n",
        "\n",
        "        # Now we shift the tgt by one so with the <SOS> we predict the token at pos 1\n",
        "        y_input = y[:,:-1]\n",
        "        y_expected = y[:,1:]\n",
        "        \n",
        "        # Get mask to mask out the next words\n",
        "        sequence_length = y_input.size(1)\n",
        "        tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n",
        "\n",
        "        # Standard training except we pass in y_input and tgt_mask\n",
        "        pred = model(X, y_input, tgt_mask)\n",
        "\n",
        "        # Permute pred to have batch size first again\n",
        "        pred = pred.permute(1, 2, 0)      \n",
        "        loss = loss_fn(pred, y_expected)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        #torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        opt.step()\n",
        "    \n",
        "        total_loss += loss.detach().item()\n",
        "        \n",
        "    return total_loss / len(dataloader)"
      ],
      "id": "7bc6949f-2d59-44c3-8198-037e115106aa",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c23630c9-ce84-4996-8d8c-ff7919303331"
      },
      "source": [
        "def validation_loop(model, loss_fn, dataloader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            X = batch[0].long()\n",
        "            y = batch[1].long()\n",
        "           # X, y = batch[:, 0], batch[:, 1]\n",
        "          #  X, y = torch.tensor(X, dtype=torch.long, device=device), torch.tensor(y, dtype=torch.long, device=device)\n",
        "            X, y = torch.tensor(X).to(device), torch.tensor(y).to(device)\n",
        "            # Now we shift the tgt by one so with the <SOS> we predict the token at pos 1\n",
        "            y_input = y[:,:-1]\n",
        "            y_expected = y[:,1:]\n",
        "            \n",
        "            # Get mask to mask out the next words\n",
        "            sequence_length = y_input.size(1)\n",
        "            tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n",
        "\n",
        "            # Standard training except we pass in y_input and src_mask\n",
        "            pred = model(X, y_input, tgt_mask)\n",
        "\n",
        "            # Permute pred to have batch size first again\n",
        "            pred = pred.permute(1, 2, 0)\n",
        "            # print(\"expected:\",y_expected.shape)\n",
        "            # print(\"pred:\",pred.shape)      \n",
        "            loss = loss_fn(pred, y_expected)\n",
        "            total_loss += loss.detach().item()\n",
        "        \n",
        "    return total_loss / len(dataloader)"
      ],
      "id": "c23630c9-ce84-4996-8d8c-ff7919303331",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e57ba93-cc8f-4b12-870f-6aed4dce94ab"
      },
      "source": [
        "def fit(model, opt, loss_fn, train_dataloader, val_dataloader, epochs):\n",
        "    # Used for plotting later on\n",
        "    train_loss_list, validation_loss_list = [], []\n",
        "    \n",
        "    print(\"Training and validating model\")\n",
        "    for epoch in range(epochs):\n",
        "        print(\"-\"*25, f\"Epoch {epoch + 1}\",\"-\"*25)\n",
        "        \n",
        "        train_loss = train_loop(model, opt, loss_fn, train_dataloader)\n",
        "        train_loss_list += [train_loss]\n",
        "        \n",
        "        validation_loss = validation_loop(model, loss_fn, val_dataloader)\n",
        "        validation_loss_list += [validation_loss]\n",
        "        \n",
        "        print(f\"Training loss: {train_loss:.4f}\")\n",
        "        print(f\"Validation loss: {validation_loss:.4f}\")\n",
        "        print()\n",
        "        \n",
        "    return train_loss_list, validation_loss_list\n",
        "    \n",
        "train_loss_list, validation_loss_list = [], []"
      ],
      "id": "5e57ba93-cc8f-4b12-870f-6aed4dce94ab",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_lt, val_loss_lt = fit(model, opt, loss_fn, train_dataloader, val_dataloader, 150)\n",
        "train_loss_list += train_loss_lt \n",
        "validation_loss_list += val_loss_lt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnhSJWQ-MlNM",
        "outputId": "e67b6fd2-3758-4221-a2b3-0c021fda0e59"
      },
      "id": "xnhSJWQ-MlNM",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and validating model\n",
            "------------------------- Epoch 1 -------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 3.7339\n",
            "Validation loss: 3.3229\n",
            "\n",
            "------------------------- Epoch 2 -------------------------\n",
            "Training loss: 3.1600\n",
            "Validation loss: 2.9466\n",
            "\n",
            "------------------------- Epoch 3 -------------------------\n",
            "Training loss: 2.8389\n",
            "Validation loss: 2.5547\n",
            "\n",
            "------------------------- Epoch 4 -------------------------\n",
            "Training loss: 2.6302\n",
            "Validation loss: 2.4291\n",
            "\n",
            "------------------------- Epoch 5 -------------------------\n",
            "Training loss: 2.5505\n",
            "Validation loss: 2.3502\n",
            "\n",
            "------------------------- Epoch 6 -------------------------\n",
            "Training loss: 2.4855\n",
            "Validation loss: 2.3388\n",
            "\n",
            "------------------------- Epoch 7 -------------------------\n",
            "Training loss: 2.4434\n",
            "Validation loss: 2.2663\n",
            "\n",
            "------------------------- Epoch 8 -------------------------\n",
            "Training loss: 2.4084\n",
            "Validation loss: 2.2496\n",
            "\n",
            "------------------------- Epoch 9 -------------------------\n",
            "Training loss: 2.3859\n",
            "Validation loss: 2.2226\n",
            "\n",
            "------------------------- Epoch 10 -------------------------\n",
            "Training loss: 2.3634\n",
            "Validation loss: 2.2396\n",
            "\n",
            "------------------------- Epoch 11 -------------------------\n",
            "Training loss: 2.3539\n",
            "Validation loss: 2.1918\n",
            "\n",
            "------------------------- Epoch 12 -------------------------\n",
            "Training loss: 2.3295\n",
            "Validation loss: 2.1842\n",
            "\n",
            "------------------------- Epoch 13 -------------------------\n",
            "Training loss: 2.3183\n",
            "Validation loss: 2.1700\n",
            "\n",
            "------------------------- Epoch 14 -------------------------\n",
            "Training loss: 2.2963\n",
            "Validation loss: 2.1506\n",
            "\n",
            "------------------------- Epoch 15 -------------------------\n",
            "Training loss: 2.2818\n",
            "Validation loss: 2.1237\n",
            "\n",
            "------------------------- Epoch 16 -------------------------\n",
            "Training loss: 2.2655\n",
            "Validation loss: 2.1265\n",
            "\n",
            "------------------------- Epoch 17 -------------------------\n",
            "Training loss: 2.2518\n",
            "Validation loss: 2.0917\n",
            "\n",
            "------------------------- Epoch 18 -------------------------\n",
            "Training loss: 2.2412\n",
            "Validation loss: 2.0954\n",
            "\n",
            "------------------------- Epoch 19 -------------------------\n",
            "Training loss: 2.2222\n",
            "Validation loss: 2.0824\n",
            "\n",
            "------------------------- Epoch 20 -------------------------\n",
            "Training loss: 2.2276\n",
            "Validation loss: 2.1138\n",
            "\n",
            "------------------------- Epoch 21 -------------------------\n",
            "Training loss: 2.2105\n",
            "Validation loss: 2.0672\n",
            "\n",
            "------------------------- Epoch 22 -------------------------\n",
            "Training loss: 2.2038\n",
            "Validation loss: 2.0518\n",
            "\n",
            "------------------------- Epoch 23 -------------------------\n",
            "Training loss: 2.1937\n",
            "Validation loss: 2.0617\n",
            "\n",
            "------------------------- Epoch 24 -------------------------\n",
            "Training loss: 2.1906\n",
            "Validation loss: 2.0421\n",
            "\n",
            "------------------------- Epoch 25 -------------------------\n",
            "Training loss: 2.1769\n",
            "Validation loss: 2.0525\n",
            "\n",
            "------------------------- Epoch 26 -------------------------\n",
            "Training loss: 2.1656\n",
            "Validation loss: 2.0315\n",
            "\n",
            "------------------------- Epoch 27 -------------------------\n",
            "Training loss: 2.1527\n",
            "Validation loss: 2.0177\n",
            "\n",
            "------------------------- Epoch 28 -------------------------\n",
            "Training loss: 2.1598\n",
            "Validation loss: 2.0253\n",
            "\n",
            "------------------------- Epoch 29 -------------------------\n",
            "Training loss: 2.1440\n",
            "Validation loss: 2.0097\n",
            "\n",
            "------------------------- Epoch 30 -------------------------\n",
            "Training loss: 2.1375\n",
            "Validation loss: 2.0070\n",
            "\n",
            "------------------------- Epoch 31 -------------------------\n",
            "Training loss: 2.1375\n",
            "Validation loss: 2.0357\n",
            "\n",
            "------------------------- Epoch 32 -------------------------\n",
            "Training loss: 2.1250\n",
            "Validation loss: 2.0131\n",
            "\n",
            "------------------------- Epoch 33 -------------------------\n",
            "Training loss: 2.1246\n",
            "Validation loss: 2.0009\n",
            "\n",
            "------------------------- Epoch 34 -------------------------\n",
            "Training loss: 2.1137\n",
            "Validation loss: 1.9953\n",
            "\n",
            "------------------------- Epoch 35 -------------------------\n",
            "Training loss: 2.1124\n",
            "Validation loss: 1.9840\n",
            "\n",
            "------------------------- Epoch 36 -------------------------\n",
            "Training loss: 2.1061\n",
            "Validation loss: 1.9748\n",
            "\n",
            "------------------------- Epoch 37 -------------------------\n",
            "Training loss: 2.1029\n",
            "Validation loss: 1.9745\n",
            "\n",
            "------------------------- Epoch 38 -------------------------\n",
            "Training loss: 2.0987\n",
            "Validation loss: 1.9868\n",
            "\n",
            "------------------------- Epoch 39 -------------------------\n",
            "Training loss: 2.0985\n",
            "Validation loss: 1.9894\n",
            "\n",
            "------------------------- Epoch 40 -------------------------\n",
            "Training loss: 2.1000\n",
            "Validation loss: 1.9715\n",
            "\n",
            "------------------------- Epoch 41 -------------------------\n",
            "Training loss: 2.0930\n",
            "Validation loss: 1.9762\n",
            "\n",
            "------------------------- Epoch 42 -------------------------\n",
            "Training loss: 2.0874\n",
            "Validation loss: 1.9817\n",
            "\n",
            "------------------------- Epoch 43 -------------------------\n",
            "Training loss: 2.0850\n",
            "Validation loss: 1.9766\n",
            "\n",
            "------------------------- Epoch 44 -------------------------\n",
            "Training loss: 2.0828\n",
            "Validation loss: 1.9653\n",
            "\n",
            "------------------------- Epoch 45 -------------------------\n",
            "Training loss: 2.0781\n",
            "Validation loss: 1.9643\n",
            "\n",
            "------------------------- Epoch 46 -------------------------\n",
            "Training loss: 2.0809\n",
            "Validation loss: 1.9819\n",
            "\n",
            "------------------------- Epoch 47 -------------------------\n",
            "Training loss: 2.0739\n",
            "Validation loss: 1.9608\n",
            "\n",
            "------------------------- Epoch 48 -------------------------\n",
            "Training loss: 2.0743\n",
            "Validation loss: 1.9648\n",
            "\n",
            "------------------------- Epoch 49 -------------------------\n",
            "Training loss: 2.0717\n",
            "Validation loss: 2.0067\n",
            "\n",
            "------------------------- Epoch 50 -------------------------\n",
            "Training loss: 2.0736\n",
            "Validation loss: 1.9674\n",
            "\n",
            "------------------------- Epoch 51 -------------------------\n",
            "Training loss: 2.0631\n",
            "Validation loss: 1.9582\n",
            "\n",
            "------------------------- Epoch 52 -------------------------\n",
            "Training loss: 2.0617\n",
            "Validation loss: 1.9595\n",
            "\n",
            "------------------------- Epoch 53 -------------------------\n",
            "Training loss: 2.0664\n",
            "Validation loss: 1.9407\n",
            "\n",
            "------------------------- Epoch 54 -------------------------\n",
            "Training loss: 2.0641\n",
            "Validation loss: 1.9560\n",
            "\n",
            "------------------------- Epoch 55 -------------------------\n",
            "Training loss: 2.0560\n",
            "Validation loss: 1.9449\n",
            "\n",
            "------------------------- Epoch 56 -------------------------\n",
            "Training loss: 2.0557\n",
            "Validation loss: 1.9928\n",
            "\n",
            "------------------------- Epoch 57 -------------------------\n",
            "Training loss: 2.0499\n",
            "Validation loss: 1.9441\n",
            "\n",
            "------------------------- Epoch 58 -------------------------\n",
            "Training loss: 2.0498\n",
            "Validation loss: 1.9531\n",
            "\n",
            "------------------------- Epoch 59 -------------------------\n",
            "Training loss: 2.0489\n",
            "Validation loss: 1.9594\n",
            "\n",
            "------------------------- Epoch 60 -------------------------\n",
            "Training loss: 2.0469\n",
            "Validation loss: 1.9486\n",
            "\n",
            "------------------------- Epoch 61 -------------------------\n",
            "Training loss: 2.0417\n",
            "Validation loss: 1.9394\n",
            "\n",
            "------------------------- Epoch 62 -------------------------\n",
            "Training loss: 2.0394\n",
            "Validation loss: 1.9487\n",
            "\n",
            "------------------------- Epoch 63 -------------------------\n",
            "Training loss: 2.0384\n",
            "Validation loss: 1.9417\n",
            "\n",
            "------------------------- Epoch 64 -------------------------\n",
            "Training loss: 2.0432\n",
            "Validation loss: 1.9581\n",
            "\n",
            "------------------------- Epoch 65 -------------------------\n",
            "Training loss: 2.0430\n",
            "Validation loss: 1.9620\n",
            "\n",
            "------------------------- Epoch 66 -------------------------\n",
            "Training loss: 2.0340\n",
            "Validation loss: 1.9307\n",
            "\n",
            "------------------------- Epoch 67 -------------------------\n",
            "Training loss: 2.0330\n",
            "Validation loss: 1.9440\n",
            "\n",
            "------------------------- Epoch 68 -------------------------\n",
            "Training loss: 2.0315\n",
            "Validation loss: 1.9386\n",
            "\n",
            "------------------------- Epoch 69 -------------------------\n",
            "Training loss: 2.0292\n",
            "Validation loss: 1.9684\n",
            "\n",
            "------------------------- Epoch 70 -------------------------\n",
            "Training loss: 2.0254\n",
            "Validation loss: 1.9300\n",
            "\n",
            "------------------------- Epoch 71 -------------------------\n",
            "Training loss: 2.0262\n",
            "Validation loss: 1.9414\n",
            "\n",
            "------------------------- Epoch 72 -------------------------\n",
            "Training loss: 2.0205\n",
            "Validation loss: 1.9248\n",
            "\n",
            "------------------------- Epoch 73 -------------------------\n",
            "Training loss: 2.0279\n",
            "Validation loss: 1.9478\n",
            "\n",
            "------------------------- Epoch 74 -------------------------\n",
            "Training loss: 2.0204\n",
            "Validation loss: 1.9362\n",
            "\n",
            "------------------------- Epoch 75 -------------------------\n",
            "Training loss: 2.0208\n",
            "Validation loss: 1.9383\n",
            "\n",
            "------------------------- Epoch 76 -------------------------\n",
            "Training loss: 2.0179\n",
            "Validation loss: 1.9451\n",
            "\n",
            "------------------------- Epoch 77 -------------------------\n",
            "Training loss: 2.0151\n",
            "Validation loss: 1.9244\n",
            "\n",
            "------------------------- Epoch 78 -------------------------\n",
            "Training loss: 2.1087\n",
            "Validation loss: 1.9938\n",
            "\n",
            "------------------------- Epoch 79 -------------------------\n",
            "Training loss: 2.0399\n",
            "Validation loss: 1.9344\n",
            "\n",
            "------------------------- Epoch 80 -------------------------\n",
            "Training loss: 2.0238\n",
            "Validation loss: 1.9284\n",
            "\n",
            "------------------------- Epoch 81 -------------------------\n",
            "Training loss: 2.0200\n",
            "Validation loss: 1.9233\n",
            "\n",
            "------------------------- Epoch 82 -------------------------\n",
            "Training loss: 2.0116\n",
            "Validation loss: 1.9208\n",
            "\n",
            "------------------------- Epoch 83 -------------------------\n",
            "Training loss: 2.0105\n",
            "Validation loss: 1.9216\n",
            "\n",
            "------------------------- Epoch 84 -------------------------\n",
            "Training loss: 2.0086\n",
            "Validation loss: 1.9300\n",
            "\n",
            "------------------------- Epoch 85 -------------------------\n",
            "Training loss: 2.0094\n",
            "Validation loss: 1.9235\n",
            "\n",
            "------------------------- Epoch 86 -------------------------\n",
            "Training loss: 2.0202\n",
            "Validation loss: 1.9221\n",
            "\n",
            "------------------------- Epoch 87 -------------------------\n",
            "Training loss: 2.0050\n",
            "Validation loss: 1.9729\n",
            "\n",
            "------------------------- Epoch 88 -------------------------\n",
            "Training loss: 2.0097\n",
            "Validation loss: 1.9255\n",
            "\n",
            "------------------------- Epoch 89 -------------------------\n",
            "Training loss: 2.0066\n",
            "Validation loss: 1.9334\n",
            "\n",
            "------------------------- Epoch 90 -------------------------\n",
            "Training loss: 1.9999\n",
            "Validation loss: 1.9317\n",
            "\n",
            "------------------------- Epoch 91 -------------------------\n",
            "Training loss: 2.0043\n",
            "Validation loss: 1.9282\n",
            "\n",
            "------------------------- Epoch 92 -------------------------\n",
            "Training loss: 2.0048\n",
            "Validation loss: 1.9212\n",
            "\n",
            "------------------------- Epoch 93 -------------------------\n",
            "Training loss: 2.0043\n",
            "Validation loss: 1.9205\n",
            "\n",
            "------------------------- Epoch 94 -------------------------\n",
            "Training loss: 1.9993\n",
            "Validation loss: 1.9246\n",
            "\n",
            "------------------------- Epoch 95 -------------------------\n",
            "Training loss: 2.0032\n",
            "Validation loss: 1.9703\n",
            "\n",
            "------------------------- Epoch 96 -------------------------\n",
            "Training loss: 1.9970\n",
            "Validation loss: 1.9295\n",
            "\n",
            "------------------------- Epoch 97 -------------------------\n",
            "Training loss: 1.9983\n",
            "Validation loss: 1.9149\n",
            "\n",
            "------------------------- Epoch 98 -------------------------\n",
            "Training loss: 1.9951\n",
            "Validation loss: 1.9278\n",
            "\n",
            "------------------------- Epoch 99 -------------------------\n",
            "Training loss: 2.0014\n",
            "Validation loss: 1.9263\n",
            "\n",
            "------------------------- Epoch 100 -------------------------\n",
            "Training loss: 1.9976\n",
            "Validation loss: 1.9288\n",
            "\n",
            "------------------------- Epoch 101 -------------------------\n",
            "Training loss: 1.9917\n",
            "Validation loss: 1.9133\n",
            "\n",
            "------------------------- Epoch 102 -------------------------\n",
            "Training loss: 2.0161\n",
            "Validation loss: 1.9185\n",
            "\n",
            "------------------------- Epoch 103 -------------------------\n",
            "Training loss: 2.0025\n",
            "Validation loss: 1.9164\n",
            "\n",
            "------------------------- Epoch 104 -------------------------\n",
            "Training loss: 1.9955\n",
            "Validation loss: 1.9272\n",
            "\n",
            "------------------------- Epoch 105 -------------------------\n",
            "Training loss: 1.9901\n",
            "Validation loss: 1.9120\n",
            "\n",
            "------------------------- Epoch 106 -------------------------\n",
            "Training loss: 1.9858\n",
            "Validation loss: 1.9134\n",
            "\n",
            "------------------------- Epoch 107 -------------------------\n",
            "Training loss: 1.9880\n",
            "Validation loss: 1.9215\n",
            "\n",
            "------------------------- Epoch 108 -------------------------\n",
            "Training loss: 1.9878\n",
            "Validation loss: 1.9282\n",
            "\n",
            "------------------------- Epoch 109 -------------------------\n",
            "Training loss: 1.9895\n",
            "Validation loss: 1.9120\n",
            "\n",
            "------------------------- Epoch 110 -------------------------\n",
            "Training loss: 1.9859\n",
            "Validation loss: 1.9124\n",
            "\n",
            "------------------------- Epoch 111 -------------------------\n",
            "Training loss: 1.9890\n",
            "Validation loss: 1.9087\n",
            "\n",
            "------------------------- Epoch 112 -------------------------\n",
            "Training loss: 1.9879\n",
            "Validation loss: 1.9175\n",
            "\n",
            "------------------------- Epoch 113 -------------------------\n",
            "Training loss: 1.9809\n",
            "Validation loss: 1.9194\n",
            "\n",
            "------------------------- Epoch 114 -------------------------\n",
            "Training loss: 1.9918\n",
            "Validation loss: 1.9145\n",
            "\n",
            "------------------------- Epoch 115 -------------------------\n",
            "Training loss: 1.9837\n",
            "Validation loss: 1.9159\n",
            "\n",
            "------------------------- Epoch 116 -------------------------\n",
            "Training loss: 1.9862\n",
            "Validation loss: 1.9102\n",
            "\n",
            "------------------------- Epoch 117 -------------------------\n",
            "Training loss: 1.9809\n",
            "Validation loss: 1.9194\n",
            "\n",
            "------------------------- Epoch 118 -------------------------\n",
            "Training loss: 1.9906\n",
            "Validation loss: 1.9134\n",
            "\n",
            "------------------------- Epoch 119 -------------------------\n",
            "Training loss: 1.9825\n",
            "Validation loss: 1.9064\n",
            "\n",
            "------------------------- Epoch 120 -------------------------\n",
            "Training loss: 1.9777\n",
            "Validation loss: 1.9610\n",
            "\n",
            "------------------------- Epoch 121 -------------------------\n",
            "Training loss: 1.9817\n",
            "Validation loss: 1.9039\n",
            "\n",
            "------------------------- Epoch 122 -------------------------\n",
            "Training loss: 1.9781\n",
            "Validation loss: 1.9102\n",
            "\n",
            "------------------------- Epoch 123 -------------------------\n",
            "Training loss: 1.9733\n",
            "Validation loss: 1.9104\n",
            "\n",
            "------------------------- Epoch 124 -------------------------\n",
            "Training loss: 1.9771\n",
            "Validation loss: 1.9188\n",
            "\n",
            "------------------------- Epoch 125 -------------------------\n",
            "Training loss: 1.9759\n",
            "Validation loss: 1.9129\n",
            "\n",
            "------------------------- Epoch 126 -------------------------\n",
            "Training loss: 1.9807\n",
            "Validation loss: 1.9606\n",
            "\n",
            "------------------------- Epoch 127 -------------------------\n",
            "Training loss: 1.9826\n",
            "Validation loss: 1.9133\n",
            "\n",
            "------------------------- Epoch 128 -------------------------\n",
            "Training loss: 1.9717\n",
            "Validation loss: 1.9213\n",
            "\n",
            "------------------------- Epoch 129 -------------------------\n",
            "Training loss: 1.9704\n",
            "Validation loss: 1.9075\n",
            "\n",
            "------------------------- Epoch 130 -------------------------\n",
            "Training loss: 1.9734\n",
            "Validation loss: 1.9155\n",
            "\n",
            "------------------------- Epoch 131 -------------------------\n",
            "Training loss: 1.9681\n",
            "Validation loss: 1.9119\n",
            "\n",
            "------------------------- Epoch 132 -------------------------\n",
            "Training loss: 1.9746\n",
            "Validation loss: 1.9192\n",
            "\n",
            "------------------------- Epoch 133 -------------------------\n",
            "Training loss: 1.9698\n",
            "Validation loss: 1.9004\n",
            "\n",
            "------------------------- Epoch 134 -------------------------\n",
            "Training loss: 1.9769\n",
            "Validation loss: 1.8969\n",
            "\n",
            "------------------------- Epoch 135 -------------------------\n",
            "Training loss: 1.9729\n",
            "Validation loss: 1.9142\n",
            "\n",
            "------------------------- Epoch 136 -------------------------\n",
            "Training loss: 1.9719\n",
            "Validation loss: 1.9087\n",
            "\n",
            "------------------------- Epoch 137 -------------------------\n",
            "Training loss: 1.9736\n",
            "Validation loss: 1.9053\n",
            "\n",
            "------------------------- Epoch 138 -------------------------\n",
            "Training loss: 1.9675\n",
            "Validation loss: 1.9224\n",
            "\n",
            "------------------------- Epoch 139 -------------------------\n",
            "Training loss: 1.9655\n",
            "Validation loss: 1.9504\n",
            "\n",
            "------------------------- Epoch 140 -------------------------\n",
            "Training loss: 1.9691\n",
            "Validation loss: 1.9029\n",
            "\n",
            "------------------------- Epoch 141 -------------------------\n",
            "Training loss: 1.9698\n",
            "Validation loss: 1.9047\n",
            "\n",
            "------------------------- Epoch 142 -------------------------\n",
            "Training loss: 1.9694\n",
            "Validation loss: 1.9408\n",
            "\n",
            "------------------------- Epoch 143 -------------------------\n",
            "Training loss: 1.9864\n",
            "Validation loss: 1.9073\n",
            "\n",
            "------------------------- Epoch 144 -------------------------\n",
            "Training loss: 1.9631\n",
            "Validation loss: 1.9246\n",
            "\n",
            "------------------------- Epoch 145 -------------------------\n",
            "Training loss: 1.9673\n",
            "Validation loss: 1.9192\n",
            "\n",
            "------------------------- Epoch 146 -------------------------\n",
            "Training loss: 1.9642\n",
            "Validation loss: 1.9402\n",
            "\n",
            "------------------------- Epoch 147 -------------------------\n",
            "Training loss: 1.9660\n",
            "Validation loss: 1.9018\n",
            "\n",
            "------------------------- Epoch 148 -------------------------\n",
            "Training loss: 1.9611\n",
            "Validation loss: 1.9244\n",
            "\n",
            "------------------------- Epoch 149 -------------------------\n",
            "Training loss: 1.9607\n",
            "Validation loss: 1.9157\n",
            "\n",
            "------------------------- Epoch 150 -------------------------\n",
            "Training loss: 1.9573\n",
            "Validation loss: 1.9007\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40f805ad-7748-4785-9066-c5500287a4af",
        "outputId": "28edd20e-9e7b-49f8-9f2c-a6fbe51fb23d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(train_loss_list, label = \"Train loss\")\n",
        "plt.plot(validation_loss_list, label = \"Validation loss\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss vs Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "40f805ad-7748-4785-9066-c5500287a4af",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_loop(model, loss_fn, dataloader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    mape = 0\n",
        "    smape = 0\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            X = batch[0].long()\n",
        "            y = batch[1].long()\n",
        "           # X, y = batch[:, 0], batch[:, 1]\n",
        "          #  X, y = torch.tensor(X, dtype=torch.long, device=device), torch.tensor(y, dtype=torch.long, device=device)\n",
        "            X, y = torch.tensor(X).to(device), torch.tensor(y).to(device)\n",
        "            # Now we shift the tgt by one so with the <SOS> we predict the token at pos 1\n",
        "            y_input = y[:,:-1]\n",
        "            y_expected = y[:,1:]\n",
        "            # print(y_expected)\n",
        "            \n",
        "            # Get mask to mask out the next words\n",
        "            sequence_length = y_input.size(1)\n",
        "            tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n",
        "\n",
        "            # Standard training except we pass in y_input and src_mask\n",
        "            pred = model(X, y_input, tgt_mask)\n",
        "\n",
        "            # Permute pred to have batch size first again\n",
        "            pred = pred.permute(1, 2, 0)\n",
        "            # print(\"expected:\",y_expected.shape)\n",
        "            # print(\"pred:\",pred.shape)\n",
        "\n",
        "            loss = loss_fn(pred, y_expected)\n",
        "            total_loss += loss.detach().item()\n",
        "\n",
        "\n",
        "            pred_class = torch.argmax(pred, dim=1)\n",
        "            pred_class = pred_class.reshape(-1)\n",
        "            y_expected = y_expected.reshape(-1)\n",
        "\n",
        "            epoch_mape = torch.abs(100 * (y_expected - pred_class) / (y_expected + 0.01)).sum().data\n",
        "            epoch_smape = torch.abs(200 * (y_expected - pred_class) / (y_expected + pred_class + 0.01)).sum().data\n",
        "\n",
        "            mape += epoch_mape\n",
        "            smape += epoch_smape            \n",
        "\n",
        "            y_pred += pred_class.tolist()\n",
        "            y_true += y_expected.tolist()\n",
        "        \n",
        "    return total_loss / len(dataloader), y_true, y_pred, mape, smape\n",
        "test_loss, y_true, y_pred, mape, smape = test_loop(model, loss_fn, test_loader)\n",
        "\n",
        "mape = mape / (len(test_dataset) * 8)\n",
        "smape = smape / (len(test_dataset) * 8)\n",
        "\n",
        "print(\"test_loss\", test_loss)\n",
        "print(\"MAPE \", mape.item())\n",
        "print(\"SMAPE \", smape.item())\n",
        "\n",
        "import sklearn.metrics as metrics\n",
        "mae = metrics.mean_absolute_error(y_true, y_pred) * 8\n",
        "mse = metrics.mean_squared_error(y_true, y_pred) * 8\n",
        "rmse = mse ** (1/2)\n",
        "\n",
        "print(\"MAE: \", mae)\n",
        "print(\"MSE: \", mse)\n",
        "print(\"RMSE: \", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrtBV8hoaYBu",
        "outputId": "1cfefc90-d96b-4964-ee26-b2f0f34c33d3"
      },
      "id": "KrtBV8hoaYBu",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_loss 1.8713531121611595\n",
            "MAPE  371.84857177734375\n",
            "SMAPE  27.716693878173828\n",
            "MAE:  23.48210395269219\n",
            "MSE:  276.07793339558043\n",
            "RMSE:  16.615593079862677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num = 0\n",
        "for i in range(len(y_pred)):\n",
        "  if y_pred[i] == y_true[i]:\n",
        "    num += 1\n",
        "precision = num / len(y_pred)\n",
        "print(\"Precision: \", precision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df1MV0DefnhV",
        "outputId": "be96c1db-615b-419f-fea5-6175184b476c"
      },
      "id": "df1MV0DefnhV",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision:  0.4343604108309991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5df24c30-15b0-471a-ac4d-a0975fbc6a7d",
        "outputId": "b6269a0c-6933-4eb5-cae6-feab51a3c171",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def predict(model, input_sequence, max_length=15, SOS_token=150, EOS_token=152):\n",
        "    model.eval()\n",
        "    \n",
        "    y_input = torch.tensor([[SOS_token]], dtype=torch.long, device=device)\n",
        "\n",
        "    num_tokens = len(input_sequence[0])\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        # Get source mask\n",
        "        tgt_mask = model.get_tgt_mask(y_input.size(1)).to(device)\n",
        "        \n",
        "        pred = model(input_sequence, y_input, tgt_mask)\n",
        "        \n",
        "        next_item = pred.topk(1)[1].view(-1)[-1].item() # num with highest probability\n",
        "        next_item = torch.tensor([[next_item]], device=device)\n",
        "\n",
        "        # Concatenate previous input with predicted best word\n",
        "        y_input = torch.cat((y_input, next_item), dim=1)\n",
        "\n",
        "        # Stop if model predicts end of sentence\n",
        "        if next_item.view(-1).item() == EOS_token:\n",
        "            break\n",
        "\n",
        "    return y_input.view(-1).tolist()\n",
        "  \n",
        "  \n",
        "# Here we test some examples to observe how the model predicts\n",
        "examples = []\n",
        "m = 0\n",
        "for batch in train_dataloader:\n",
        "  X = batch[0].long()\n",
        "  y = batch[1].long()\n",
        "  #X, y = torch.tensor(X).to(device), torch.tensor(y).to(device)\n",
        "  print(X[0])\n",
        "  m = m + 1\n",
        "  if m > 0:\n",
        "    break\n",
        "\n",
        "examples = [X[0],X[1],X[2],X[3]]\n",
        "print(examples)\n",
        "print(y[0])\n",
        "print(y[1])\n",
        "print(y[2])\n",
        "print(y[3])\n",
        "\n",
        "examples = [\n",
        "    #torch.tensor([train_dataloader[1]], dtype=torch.long, device=device),\n",
        "    torch.tensor([[150,   5,  10,   4,   0,   2,  10,   2,   9,   2,   9,   3,   0,   3, 9,   1,   7,   2,   7,   4,   0,   3,   2,   2,   7, 152]], dtype=torch.long, device=device),\n",
        "    torch.tensor([[150,  30,  81,  72,   0,  18,  38,   7,  66,  36,  79,  70,   0,  24,\n",
        "         31,   6,  71,  50,  80,  83,   0,  14,  28,   6,  79, 152]], dtype=torch.long, device=device),\n",
        "    torch.tensor([[150,   9,  15,  10,   0,   1,   3,   2,  18,   5,  13,   7,   0,   1,\n",
        "          8,   0,  15,   9,  11,   8,   0,   1,   5,   0,   9, 152]], dtype=torch.long, device=device),\n",
        "    torch.tensor([[150,  42,  31,  38,   0,  13,  60,  16,  31,  35,  34,  27,   0,  20,\n",
        "         43,  12,  32,  47,  34,  37,   0,  16,  58,  14,  43, 152]], dtype=torch.long, device=device),\n",
        "   # torch.tensor([[150, 13,  7, 13,  0,  4, 12,  2,  9, 100]], dtype=torch.long, device=device)\n",
        "    # torch.tensor([[2, 0, 0, 0, 4, 0, 3]], dtype=torch.long, device=device),\n",
        "    # torch.tensor([[2, 1, 1, 1, 1, 1, 3]], dtype=torch.long, device=device),\n",
        "    # torch.tensor([[2, 1, 0, 1, 6, 1, 3]], dtype=torch.long, device=device),\n",
        "    # torch.tensor([[2, 0, 1, 0, 1, 0, 3]], dtype=torch.long, device=device),\n",
        "    # torch.tensor([[2, 0, 1, 0, 7, 0, 3]], dtype=torch.long, device=device),\n",
        "    # torch.tensor([[2, 0, 1, 0, 1, 1, 3]], dtype=torch.long, device=device)\n",
        "]\n",
        "\n",
        "for idx, example in enumerate(examples):\n",
        "    result = predict(model, example)\n",
        "    print(f\"Example {idx}\")\n",
        "    print(f\"Input: {example.view(-1).tolist()[1:-1]}\")\n",
        "    print(f\"Continuation: {result[1:-1]}\")\n",
        "    print()"
      ],
      "id": "5df24c30-15b0-471a-ac4d-a0975fbc6a7d",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([150,   1,   1,   2,   0,   1,   3,   1,   3,   2,   2,   4,   0,   0,\n",
            "          5,   1,   1,   4,   4,   6,   0,   3,   7,   1,   5, 152])\n",
            "[tensor([150,   1,   1,   2,   0,   1,   3,   1,   3,   2,   2,   4,   0,   0,\n",
            "          5,   1,   1,   4,   4,   6,   0,   3,   7,   1,   5, 152]), tensor([150,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 152]), tensor([150,  38,  65,  37,   0,   3,  19,   3,  62,  30,  55,  45,   0,   2,\n",
            "         23,   1,  54,  32,  53,  49,   0,   4,  23,   3,  57, 152]), tensor([150,  71,  79,  77,   0,   5,  36,   9,  90,  57,  87,  63,   0,   7,\n",
            "         33,  11,  82,  55,  71,  69,   0,   5,  36,   8, 102, 152])]\n",
            "tensor([150,   1,   5,   2,   0,   2,   5,   1,   5, 152])\n",
            "tensor([150,   0,   0,   0,   0,   0,   0,   0,   0, 152])\n",
            "tensor([150,  32,  52,  48,   0,   4,  24,   5,  60, 152])\n",
            "tensor([150,  65,  98,  80,   0,   4,  35,  12, 104, 152])\n",
            "Example 0\n",
            "Input: [5, 10, 4, 0, 2, 10, 2, 9, 2, 9, 3, 0, 3, 9, 1, 7, 2, 7, 4, 0, 3, 2, 2, 7]\n",
            "Continuation: [2, 7, 4, 0, 1, 4, 0, 7]\n",
            "\n",
            "Example 1\n",
            "Input: [30, 81, 72, 0, 18, 38, 7, 66, 36, 79, 70, 0, 24, 31, 6, 71, 50, 80, 83, 0, 14, 28, 6, 79]\n",
            "Continuation: [31, 77, 69, 0, 15, 31, 7, 70]\n",
            "\n",
            "Example 2\n",
            "Input: [9, 15, 10, 0, 1, 3, 2, 18, 5, 13, 7, 0, 1, 8, 0, 15, 9, 11, 8, 0, 1, 5, 0, 9]\n",
            "Continuation: [6, 15, 8, 0, 0, 7, 0, 12]\n",
            "\n",
            "Example 3\n",
            "Input: [42, 31, 38, 0, 13, 60, 16, 31, 35, 34, 27, 0, 20, 43, 12, 32, 47, 34, 37, 0, 16, 58, 14, 43]\n",
            "Continuation: [42, 40, 38, 0, 17, 49, 15, 41]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBpKjFT93Lpr"
      },
      "source": [
        ""
      ],
      "id": "RBpKjFT93Lpr",
      "execution_count": null,
      "outputs": []
    }
  ]
}