{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "example_use_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c9d73bb-e8d5-4aeb-a928-93db9ac6241c"
      },
      "source": [
        "# Transformer boilerplate code + how to use it\n",
        "##### by Daniel Melchor (dmh672@gmail.com)"
      ],
      "id": "2c9d73bb-e8d5-4aeb-a928-93db9ac6241c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31985af0-d58e-4d01-8432-065537022502"
      },
      "source": [
        "---\n",
        "## Imports"
      ],
      "id": "31985af0-d58e-4d01-8432-065537022502"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "446258e5-7cf2-4a73-8dd7-7b7a43fdd98e",
        "outputId": "efef691b-816b-4f27-91da-2bac27e2ff41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install torch numpy matplotlib"
      ],
      "id": "446258e5-7cf2-4a73-8dd7-7b7a43fdd98e",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3539f61f-fe7d-4428-b074-327a883f7f6e"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "3539f61f-fe7d-4428-b074-327a883f7f6e",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c72c2ada-2106-4505-82f5-086e518080a5",
        "tags": []
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, dim_model, dropout_p, max_len):\n",
        "        super().__init__()\n",
        "        # Modified version from: https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
        "        # max_len determines how far the position can have an effect on a token (window)\n",
        "        \n",
        "        # Info\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        \n",
        "        # Encoding - From formula\n",
        "        pos_encoding = torch.zeros(max_len, dim_model)\n",
        "        positions_list = torch.arange(0, max_len, dtype=torch.float).view(-1, 1) # 0, 1, 2, 3, 4, 5\n",
        "        division_term = torch.exp(torch.arange(0, dim_model, 2).float() * (-math.log(10000.0)) / dim_model) # 1000^(2i/dim_model)\n",
        "        \n",
        "        # PE(pos, 2i) = sin(pos/1000^(2i/dim_model))\n",
        "        pos_encoding[:, 0::2] = torch.sin(positions_list * division_term)\n",
        "        \n",
        "        # PE(pos, 2i + 1) = cos(pos/1000^(2i/dim_model))\n",
        "        pos_encoding[:, 1::2] = torch.cos(positions_list * division_term)\n",
        "        \n",
        "        # Saving buffer (same as parameter without gradients needed)\n",
        "        pos_encoding = pos_encoding.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pos_encoding\",pos_encoding)\n",
        "        \n",
        "    def forward(self, token_embedding: torch.tensor) -> torch.tensor:\n",
        "        # Residual connection + pos encoding\n",
        "        return self.dropout(token_embedding + self.pos_encoding[:token_embedding.size(0), :])"
      ],
      "id": "c72c2ada-2106-4505-82f5-086e518080a5",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "588b2729-866c-470a-aca7-6a3c5ea0b192",
        "tags": []
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Model from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
        "    Daniel Melchor: https://medium.com/p/c80afbc9ffb1/\n",
        "    \"\"\"\n",
        "    # Constructor\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_tokens,\n",
        "        dim_model,\n",
        "        num_heads,\n",
        "        num_encoder_layers,\n",
        "        num_decoder_layers,\n",
        "        dropout_p,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # INFO\n",
        "        self.model_type = \"Transformer\"\n",
        "        self.dim_model = dim_model\n",
        "\n",
        "        # LAYERS\n",
        "        self.positional_encoder = PositionalEncoding(\n",
        "            dim_model=dim_model, dropout_p=dropout_p, max_len=5000\n",
        "        )\n",
        "        self.embedding = nn.Embedding(num_tokens, dim_model)\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=dim_model,\n",
        "            nhead=num_heads,\n",
        "            num_encoder_layers=num_encoder_layers,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            dropout=dropout_p,\n",
        "        )\n",
        "        self.out = nn.Linear(dim_model, num_tokens)\n",
        "        \n",
        "    def forward(self, src, tgt, tgt_mask=None, src_pad_mask=None, tgt_pad_mask=None):\n",
        "        # Src size must be (batch_size, src sequence length)\n",
        "        # Tgt size must be (batch_size, tgt sequence length)\n",
        "\n",
        "        # Embedding + positional encoding - Out size = (batch_size, sequence length, dim_model)\n",
        "        src = self.embedding(src) * math.sqrt(self.dim_model)\n",
        "        tgt = self.embedding(tgt) * math.sqrt(self.dim_model)\n",
        "        src = self.positional_encoder(src)\n",
        "        tgt = self.positional_encoder(tgt)\n",
        "        \n",
        "        # We could use the parameter batch_first=True, but our KDL version doesn't support it yet, so we permute\n",
        "        # to obtain size (sequence length, batch_size, dim_model),\n",
        "        src = src.permute(1,0,2)\n",
        "        tgt = tgt.permute(1,0,2)\n",
        "\n",
        "        # Transformer blocks - Out size = (sequence length, batch_size, num_tokens)\n",
        "        transformer_out = self.transformer(src, tgt, tgt_mask=tgt_mask, src_key_padding_mask=src_pad_mask, tgt_key_padding_mask=tgt_pad_mask)\n",
        "        out = self.out(transformer_out)\n",
        "        \n",
        "        return out\n",
        "      \n",
        "    def get_tgt_mask(self, size) -> torch.tensor:\n",
        "        # Generates a squeare matrix where the each row allows one word more to be seen\n",
        "        mask = torch.tril(torch.ones(size, size) == 1) # Lower triangular matrix\n",
        "        mask = mask.float()\n",
        "        mask = mask.masked_fill(mask == 0, float('-inf')) # Convert zeros to -inf\n",
        "        mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n",
        "        \n",
        "        # EX for size=5:\n",
        "        # [[0., -inf, -inf, -inf, -inf],\n",
        "        #  [0.,   0., -inf, -inf, -inf],\n",
        "        #  [0.,   0.,   0., -inf, -inf],\n",
        "        #  [0.,   0.,   0.,   0., -inf],\n",
        "        #  [0.,   0.,   0.,   0.,   0.]]\n",
        "        \n",
        "        return mask\n",
        "    \n",
        "    def create_pad_mask(self, matrix: torch.tensor, pad_token: int) -> torch.tensor:\n",
        "        # If matrix = [1,2,3,0,0,0] where pad_token=0, the result mask is\n",
        "        # [False, False, False, True, True, True]\n",
        "        return (matrix == pad_token)"
      ],
      "id": "588b2729-866c-470a-aca7-6a3c5ea0b192",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the dataset for training and validation# Notice,we need to put SOS and EOS into the dataset; Compared with seq2se1 Code"
      ],
      "metadata": {
        "id": "vOKijoZX662r"
      },
      "id": "vOKijoZX662r"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AcH-m0J6_OD",
        "outputId": "b5b1c5c2-2477-44ef-aeb1-52a83155de6d"
      },
      "id": "_AcH-m0J6_OD",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fp = open('/content/drive/My Drive/project/i580w_jan 2012_input.txt','r')\n",
        "input_data=[]\n",
        "for line in fp:\n",
        "    line=line.strip('\\n')   #将\\n去掉\n",
        "    input_data.append(line.split(' '))   #将空格作为分隔符将一个字符切割成一个字符数组\n",
        "\n",
        "fp.close()\n",
        "input_data=np.array(input_data,dtype=int)   #将其转换成numpy的数组，并定义数据类型为float\n",
        "\n",
        "fp = open('/content/drive/My Drive/project/i580w_jan 2012_target.txt','r')\n",
        "target_data=[]\n",
        "for line in fp:\n",
        "    line=line.strip('\\n')   #将\\n去掉\n",
        "    target_data.append(line.split(' '))   #将空格作为分隔符将一个字符切割成一个字符数组\n",
        "\n",
        "fp.close()\n",
        "target_data=np.array(target_data,dtype=int)   #将其转换成numpy的数组，并定义数据类型为float\n",
        "#input_data = np.delete(input_data,[3,11,19],axis = 1) #delete the null column\n",
        "#target_data = np.delete(target_data,[3],axis = 1)\n",
        "#input_data = input_data[:,16:]\n",
        "print(\"input data shape:\",input_data.shape)\n",
        "print(\"target data shape:\",target_data.shape)\n",
        "print(input_data[:8])\n",
        "print(target_data[:8])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaZ_IC6Z7dV6",
        "outputId": "cdd68b30-3796-4122-a2e8-0e78a266d681"
      },
      "id": "YaZ_IC6Z7dV6",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input data shape: (8925, 24)\n",
            "target data shape: (8925, 8)\n",
            "[[ 3 12  4  0  0  4  1  2  1  4  1  0  1  6  1  8  2  5  6  0  5  2  1  5]\n",
            " [ 1  4  1  0  1  6  1  8  2  5  6  0  5  2  1  5  2  6  6  0  4  4  0  9]\n",
            " [ 2  5  6  0  5  2  1  5  2  6  6  0  4  4  0  9  4  8 12  0  6  2  0 12]\n",
            " [ 2  6  6  0  4  4  0  9  4  8 12  0  6  2  0 12 11 11 10  0  2  4  2  9]\n",
            " [ 4  8 12  0  6  2  0 12 11 11 10  0  2  4  2  9 15  7 14  0  8  4  0  9]\n",
            " [11 11 10  0  2  4  2  9 15  7 14  0  8  4  0  9 13  7 13  0  4 12  2  9]\n",
            " [15  7 14  0  8  4  0  9 13  7 13  0  4 12  2  9  7 14 14  0  6  3  1 12]\n",
            " [13  7 13  0  4 12  2  9  7 14 14  0  6  3  1 12  9 11 24  0  6  1  3 11]]\n",
            "[[ 2  6  6  0  4  4  0  9]\n",
            " [ 4  8 12  0  6  2  0 12]\n",
            " [11 11 10  0  2  4  2  9]\n",
            " [15  7 14  0  8  4  0  9]\n",
            " [13  7 13  0  4 12  2  9]\n",
            " [ 7 14 14  0  6  3  1 12]\n",
            " [ 9 11 24  0  6  1  3 11]\n",
            " [13 11 23  0  5  6  1 20]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_max = np.max(input_data, axis = 0)\n",
        "input_min = np.min(input_data, axis = 0)\n",
        "output_max = np.max(target_data, axis = 0)\n",
        "output_min = np.min(target_data, axis = 0)\n",
        "\n",
        "print(\"input max:{0},\\n input min:{1},\\n output max:{2},\\n output min:{3}\".format(input_max,input_min,output_max,output_min)) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHEGKszw8Tm7",
        "outputId": "2f6896f7-7321-456c-c0f6-f70de9a969de"
      },
      "id": "rHEGKszw8Tm7",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input max:[ 91 131 111   0  36  82  33 147  91 131 111   0  36  82  33 147  91 131\n",
            " 111   0  36  82  33 147],\n",
            " input min:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0],\n",
            " output max:[ 91 131 111   0  36  82  33 147],\n",
            " output min:[0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add SOS and EOS"
      ],
      "metadata": {
        "id": "XsBAUzACIwKT"
      },
      "id": "XsBAUzACIwKT"
    },
    {
      "cell_type": "code",
      "source": [
        "def addsoseos(X):\n",
        "  SOS = np.ones([X.shape[0],1])*(150)\n",
        "  EOS = np.ones([X.shape[0],1])*(152)\n",
        "  X = np.c_[X,EOS]\n",
        "  X = np.c_[SOS,X]\n",
        "  return X"
      ],
      "metadata": {
        "id": "3efdHVfHIwuM"
      },
      "id": "3efdHVfHIwuM",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalization(data):\n",
        "    _range = np.max(data) - np.min(data)\n",
        "    return (data - np.min(data)) / _range\n",
        " \n",
        "\n",
        "def standardization(data):\n",
        "    mu = np.mean(data, axis=0)\n",
        "    sigma = np.std(data, axis=0)\n",
        "    return (data - mu) / sigma"
      ],
      "metadata": {
        "id": "PZs4tRfY-YT7"
      },
      "id": "PZs4tRfY-YT7",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_data = normalization(input_data) \n",
        "# target_data = normalization(target_data)\n",
        "# print(input_data[:8])\n",
        "# print(target_data[:8])"
      ],
      "metadata": {
        "id": "2lvKWcGK-bhx"
      },
      "id": "2lvKWcGK-bhx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = addsoseos(input_data)\n",
        "target_data = addsoseos(target_data)"
      ],
      "metadata": {
        "id": "TMekALw9L53i"
      },
      "id": "TMekALw9L53i",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import torch.utils.data as Data\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(input_data, target_data, test_size=0.2, random_state = 42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1)"
      ],
      "metadata": {
        "id": "rO3OQGw6BgtT"
      },
      "id": "rO3OQGw6BgtT",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-j2831tBjUC",
        "outputId": "ec189708-2bff-4ff5-ec04-c4fceef53070"
      },
      "id": "8-j2831tBjUC",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6426, 26)\n",
            "(6426, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Batch_Size = 16\n",
        "train_dataset = Data.TensorDataset(torch.from_numpy(X_train),torch.from_numpy(y_train))\n",
        "\n",
        "#load training data\n",
        "train_dataloader = Data.DataLoader(dataset = train_dataset,\n",
        "                 batch_size = Batch_Size,\n",
        "                 shuffle = True)\n",
        "\n",
        "val_dataset = Data.TensorDataset(torch.from_numpy(X_val),torch.from_numpy(y_val))\n",
        "#load validation data\n",
        "val_dataloader = Data.DataLoader(dataset = val_dataset,\n",
        "                 batch_size = Batch_Size,\n",
        "                 shuffle = False)\n",
        "\n",
        "test_dataset = Data.TensorDataset(torch.from_numpy(X_test),torch.from_numpy(y_test))\n",
        "#load testing data\n",
        "test_loader = Data.DataLoader(dataset = test_dataset,\n",
        "                 batch_size = Batch_Size,\n",
        "                 shuffle = False)\n"
      ],
      "metadata": {
        "id": "oQ3g-yMbFArb"
      },
      "id": "oQ3g-yMbFArb",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add SOS and EOS\n",
        "# def generate_smaple(X,y):#X:6426*21; y:6426*7\n",
        "#   data = []\n",
        "#   SOS_token = np.array([2])#start of token\n",
        "#   EOS_token = np.array([3])#start of token\n",
        "#   for i in range(X.shape[0]):\n",
        "#     data_X = np.concatenate((SOS_token, X[i].ravel(), EOS_token))\n",
        "#     data_y = np.concatenate((SOS_token, y[i].ravel(), EOS_token))\n",
        "#     data.append([data_X, data_y])\n",
        "#   np.random.shuffle(data)\n",
        "#   return data"
      ],
      "metadata": {
        "id": "gHnv9CQbBuVR"
      },
      "id": "gHnv9CQbBuVR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data = generate_smaple(X_train,y_train)\n",
        "# print(train_data[1])\n",
        "# print(train_data[1][0])\n",
        "# print(train_data[1][1])\n",
        "# print(np.shape(train_data))"
      ],
      "metadata": {
        "id": "1GrkeyetCv4E"
      },
      "id": "1GrkeyetCv4E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ac39c4a-ab17-4487-a1ab-2b107e880574"
      },
      "source": [
        "def generate_random_data(n):\n",
        "    SOS_token = np.array([2])#start of token\n",
        "    EOS_token = np.array([3])#end of token\n",
        "    print(SOS_token)\n",
        "    print(EOS_token)\n",
        "    length = 5\n",
        "\n",
        "    data = []\n",
        "\n",
        "    # 1,1,1,1,1,1 -> 1,1,1,1,1\n",
        "    for i in range(n // 3):\n",
        "        X = np.concatenate((SOS_token, np.ones(length), EOS_token))\n",
        "        y = np.concatenate((SOS_token, np.ones(length), EOS_token))\n",
        "        data.append([X, y])\n",
        "\n",
        "    # 0,0,0,0 -> 0,0,0,0\n",
        "    for i in range(n // 3):\n",
        "        X = np.concatenate((SOS_token, np.zeros(length), EOS_token))\n",
        "        y = np.concatenate((SOS_token, np.zeros(length), EOS_token))\n",
        "        data.append([X, y])\n",
        "\n",
        "    # 1,0,1,0 -> 1,0,1,0,1\n",
        "    for i in range(n // 3):\n",
        "        X = np.zeros(length)\n",
        "        start = random.randint(0, 1)\n",
        "\n",
        "        X[start::2] = 1\n",
        "\n",
        "        y = np.zeros(length)\n",
        "        if X[-1] == 0:\n",
        "            y[::2] = 1\n",
        "        else:\n",
        "            y[1::2] = 1\n",
        "\n",
        "        X = np.concatenate((SOS_token, X, EOS_token))\n",
        "        y = np.concatenate((SOS_token, y, EOS_token))\n",
        "\n",
        "        data.append([X, y])\n",
        "\n",
        "    np.random.shuffle(data)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def batchify_data(data, batch_size=16, padding=False, padding_token=-1):\n",
        "    batches = []\n",
        "    for idx in range(0, len(data), batch_size):\n",
        "        # We make sure we dont get the last bit if its not batch_size size\n",
        "        if idx + batch_size < len(data):\n",
        "            # Here you would need to get the max length of the batch,\n",
        "            # and normalize the length with the PAD token.\n",
        "            if padding:\n",
        "                max_batch_length = 0\n",
        "\n",
        "                # Get longest sentence in batch\n",
        "                for seq in data[idx : idx + batch_size]:\n",
        "                    if len(seq) > max_batch_length:\n",
        "                        max_batch_length = len(seq)\n",
        "\n",
        "                # Append X padding tokens until it reaches the max length\n",
        "                for seq_idx in range(batch_size):\n",
        "                    remaining_length = max_bath_length - len(data[idx + seq_idx])\n",
        "                    data[idx + seq_idx] += [padding_token] * remaining_length\n",
        "\n",
        "            batches.append(np.array(data[idx : idx + batch_size]).astype(np.int64))\n",
        "\n",
        "    print(f\"{len(batches)} batches of size {batch_size}\")\n",
        "\n",
        "    return batches\n",
        "\n",
        "\n",
        "# train_data = generate_random_data(9000)\n",
        "# val_data = generate_random_data(3000)\n",
        "\n",
        "\n",
        "# print(train_data[1][0])\n",
        "# print(train_data[1][1])\n",
        "# print(train_data[3])\n",
        "# print(np.shape(train_data))\n",
        "# train_dataloader = batchify_data(train_data)\n",
        "# val_dataloader = batchify_data(val_data)\n",
        "# print(train_dataloader[1])"
      ],
      "id": "8ac39c4a-ab17-4487-a1ab-2b107e880574",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d04a60a-f013-4eda-b056-fc9bb1b1ea79"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = Transformer(\n",
        "    num_tokens=160, dim_model=8, num_heads=8, num_encoder_layers=2, num_decoder_layers=2, dropout_p=0.2\n",
        ").to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "id": "4d04a60a-f013-4eda-b056-fc9bb1b1ea79",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bc6949f-2d59-44c3-8198-037e115106aa"
      },
      "source": [
        "def train_loop(model, opt, loss_fn, dataloader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    \n",
        "    for batch in dataloader:\n",
        "        #X, y = batch[:, 0], batch[:, 1]\n",
        "        X = batch[0].long()\n",
        "        y = batch[1].long()\n",
        "        #print(X.dtype)\n",
        "        #print(y.dtype)\n",
        "        X, y = torch.tensor(X).to(device), torch.tensor(y).to(device)\n",
        "\n",
        "        # Now we shift the tgt by one so with the <SOS> we predict the token at pos 1\n",
        "        y_input = y[:,:-1]\n",
        "        y_expected = y[:,1:]\n",
        "        \n",
        "        # Get mask to mask out the next words\n",
        "        sequence_length = y_input.size(1)\n",
        "        tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n",
        "\n",
        "        # Standard training except we pass in y_input and tgt_mask\n",
        "        pred = model(X, y_input, tgt_mask)\n",
        "\n",
        "        # Permute pred to have batch size first again\n",
        "        pred = pred.permute(1, 2, 0)      \n",
        "        loss = loss_fn(pred, y_expected)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        #torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        opt.step()\n",
        "    \n",
        "        total_loss += loss.detach().item()\n",
        "        \n",
        "    return total_loss / len(dataloader)"
      ],
      "id": "7bc6949f-2d59-44c3-8198-037e115106aa",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c23630c9-ce84-4996-8d8c-ff7919303331"
      },
      "source": [
        "def validation_loop(model, loss_fn, dataloader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            X = batch[0].long()\n",
        "            y = batch[1].long()\n",
        "           # X, y = batch[:, 0], batch[:, 1]\n",
        "          #  X, y = torch.tensor(X, dtype=torch.long, device=device), torch.tensor(y, dtype=torch.long, device=device)\n",
        "            X, y = torch.tensor(X).to(device), torch.tensor(y).to(device)\n",
        "            # Now we shift the tgt by one so with the <SOS> we predict the token at pos 1\n",
        "            y_input = y[:,:-1]\n",
        "            y_expected = y[:,1:]\n",
        "            \n",
        "            # Get mask to mask out the next words\n",
        "            sequence_length = y_input.size(1)\n",
        "            tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n",
        "\n",
        "            # Standard training except we pass in y_input and src_mask\n",
        "            pred = model(X, y_input, tgt_mask)\n",
        "\n",
        "            # Permute pred to have batch size first again\n",
        "            pred = pred.permute(1, 2, 0)\n",
        "            # print(\"expected:\",y_expected.shape)\n",
        "            # print(\"pred:\",pred.shape)      \n",
        "            loss = loss_fn(pred, y_expected)\n",
        "            total_loss += loss.detach().item()\n",
        "        \n",
        "    return total_loss / len(dataloader)"
      ],
      "id": "c23630c9-ce84-4996-8d8c-ff7919303331",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e57ba93-cc8f-4b12-870f-6aed4dce94ab"
      },
      "source": [
        "def fit(model, opt, loss_fn, train_dataloader, val_dataloader, epochs):\n",
        "    # Used for plotting later on\n",
        "    train_loss_list, validation_loss_list = [], []\n",
        "    \n",
        "    print(\"Training and validating model\")\n",
        "    for epoch in range(epochs):\n",
        "        print(\"-\"*25, f\"Epoch {epoch + 1}\",\"-\"*25)\n",
        "        \n",
        "        train_loss = train_loop(model, opt, loss_fn, train_dataloader)\n",
        "        train_loss_list += [train_loss]\n",
        "        \n",
        "        validation_loss = validation_loop(model, loss_fn, val_dataloader)\n",
        "        validation_loss_list += [validation_loss]\n",
        "        \n",
        "        print(f\"Training loss: {train_loss:.4f}\")\n",
        "        print(f\"Validation loss: {validation_loss:.4f}\")\n",
        "        print()\n",
        "        \n",
        "    return train_loss_list, validation_loss_list\n",
        "    \n",
        "train_loss_list, validation_loss_list = [], []"
      ],
      "id": "5e57ba93-cc8f-4b12-870f-6aed4dce94ab",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_lt, val_loss_lt = fit(model, opt, loss_fn, train_dataloader, val_dataloader, 150)\n",
        "train_loss_list += train_loss_lt \n",
        "validation_loss_list += val_loss_lt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnhSJWQ-MlNM",
        "outputId": "16bdd31d-ad40-4b4c-e2d8-42e5ac932249"
      },
      "id": "xnhSJWQ-MlNM",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and validating model\n",
            "------------------------- Epoch 1 -------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 3.7433\n",
            "Validation loss: 3.2630\n",
            "\n",
            "------------------------- Epoch 2 -------------------------\n",
            "Training loss: 3.1811\n",
            "Validation loss: 2.9517\n",
            "\n",
            "------------------------- Epoch 3 -------------------------\n",
            "Training loss: 2.9573\n",
            "Validation loss: 2.7469\n",
            "\n",
            "------------------------- Epoch 4 -------------------------\n",
            "Training loss: 2.8271\n",
            "Validation loss: 2.6104\n",
            "\n",
            "------------------------- Epoch 5 -------------------------\n",
            "Training loss: 2.7441\n",
            "Validation loss: 2.5281\n",
            "\n",
            "------------------------- Epoch 6 -------------------------\n",
            "Training loss: 2.6942\n",
            "Validation loss: 2.4750\n",
            "\n",
            "------------------------- Epoch 7 -------------------------\n",
            "Training loss: 2.6467\n",
            "Validation loss: 2.4212\n",
            "\n",
            "------------------------- Epoch 8 -------------------------\n",
            "Training loss: 2.6164\n",
            "Validation loss: 2.3819\n",
            "\n",
            "------------------------- Epoch 9 -------------------------\n",
            "Training loss: 2.5819\n",
            "Validation loss: 2.3535\n",
            "\n",
            "------------------------- Epoch 10 -------------------------\n",
            "Training loss: 2.5614\n",
            "Validation loss: 2.3459\n",
            "\n",
            "------------------------- Epoch 11 -------------------------\n",
            "Training loss: 2.5411\n",
            "Validation loss: 2.3202\n",
            "\n",
            "------------------------- Epoch 12 -------------------------\n",
            "Training loss: 2.5190\n",
            "Validation loss: 2.2930\n",
            "\n",
            "------------------------- Epoch 13 -------------------------\n",
            "Training loss: 2.5057\n",
            "Validation loss: 2.2839\n",
            "\n",
            "------------------------- Epoch 14 -------------------------\n",
            "Training loss: 2.4882\n",
            "Validation loss: 2.2708\n",
            "\n",
            "------------------------- Epoch 15 -------------------------\n",
            "Training loss: 2.4756\n",
            "Validation loss: 2.2506\n",
            "\n",
            "------------------------- Epoch 16 -------------------------\n",
            "Training loss: 2.4636\n",
            "Validation loss: 2.2303\n",
            "\n",
            "------------------------- Epoch 17 -------------------------\n",
            "Training loss: 2.4493\n",
            "Validation loss: 2.2250\n",
            "\n",
            "------------------------- Epoch 18 -------------------------\n",
            "Training loss: 2.4417\n",
            "Validation loss: 2.2120\n",
            "\n",
            "------------------------- Epoch 19 -------------------------\n",
            "Training loss: 2.4343\n",
            "Validation loss: 2.1987\n",
            "\n",
            "------------------------- Epoch 20 -------------------------\n",
            "Training loss: 2.4219\n",
            "Validation loss: 2.1897\n",
            "\n",
            "------------------------- Epoch 21 -------------------------\n",
            "Training loss: 2.4119\n",
            "Validation loss: 2.1923\n",
            "\n",
            "------------------------- Epoch 22 -------------------------\n",
            "Training loss: 2.4043\n",
            "Validation loss: 2.1678\n",
            "\n",
            "------------------------- Epoch 23 -------------------------\n",
            "Training loss: 2.3972\n",
            "Validation loss: 2.1740\n",
            "\n",
            "------------------------- Epoch 24 -------------------------\n",
            "Training loss: 2.3884\n",
            "Validation loss: 2.1718\n",
            "\n",
            "------------------------- Epoch 25 -------------------------\n",
            "Training loss: 2.3744\n",
            "Validation loss: 2.1774\n",
            "\n",
            "------------------------- Epoch 26 -------------------------\n",
            "Training loss: 2.3685\n",
            "Validation loss: 2.1450\n",
            "\n",
            "------------------------- Epoch 27 -------------------------\n",
            "Training loss: 2.3658\n",
            "Validation loss: 2.1353\n",
            "\n",
            "------------------------- Epoch 28 -------------------------\n",
            "Training loss: 2.3589\n",
            "Validation loss: 2.1291\n",
            "\n",
            "------------------------- Epoch 29 -------------------------\n",
            "Training loss: 2.3552\n",
            "Validation loss: 2.1498\n",
            "\n",
            "------------------------- Epoch 30 -------------------------\n",
            "Training loss: 2.3466\n",
            "Validation loss: 2.1251\n",
            "\n",
            "------------------------- Epoch 31 -------------------------\n",
            "Training loss: 2.3385\n",
            "Validation loss: 2.1252\n",
            "\n",
            "------------------------- Epoch 32 -------------------------\n",
            "Training loss: 2.3310\n",
            "Validation loss: 2.1380\n",
            "\n",
            "------------------------- Epoch 33 -------------------------\n",
            "Training loss: 2.3344\n",
            "Validation loss: 2.1250\n",
            "\n",
            "------------------------- Epoch 34 -------------------------\n",
            "Training loss: 2.3262\n",
            "Validation loss: 2.1077\n",
            "\n",
            "------------------------- Epoch 35 -------------------------\n",
            "Training loss: 2.3192\n",
            "Validation loss: 2.1048\n",
            "\n",
            "------------------------- Epoch 36 -------------------------\n",
            "Training loss: 2.3157\n",
            "Validation loss: 2.0999\n",
            "\n",
            "------------------------- Epoch 37 -------------------------\n",
            "Training loss: 2.3146\n",
            "Validation loss: 2.1096\n",
            "\n",
            "------------------------- Epoch 38 -------------------------\n",
            "Training loss: 2.3121\n",
            "Validation loss: 2.1100\n",
            "\n",
            "------------------------- Epoch 39 -------------------------\n",
            "Training loss: 2.3073\n",
            "Validation loss: 2.0955\n",
            "\n",
            "------------------------- Epoch 40 -------------------------\n",
            "Training loss: 2.3049\n",
            "Validation loss: 2.0973\n",
            "\n",
            "------------------------- Epoch 41 -------------------------\n",
            "Training loss: 2.3012\n",
            "Validation loss: 2.0754\n",
            "\n",
            "------------------------- Epoch 42 -------------------------\n",
            "Training loss: 2.2958\n",
            "Validation loss: 2.0725\n",
            "\n",
            "------------------------- Epoch 43 -------------------------\n",
            "Training loss: 2.2920\n",
            "Validation loss: 2.0771\n",
            "\n",
            "------------------------- Epoch 44 -------------------------\n",
            "Training loss: 2.2863\n",
            "Validation loss: 2.0688\n",
            "\n",
            "------------------------- Epoch 45 -------------------------\n",
            "Training loss: 2.2877\n",
            "Validation loss: 2.0767\n",
            "\n",
            "------------------------- Epoch 46 -------------------------\n",
            "Training loss: 2.2800\n",
            "Validation loss: 2.0646\n",
            "\n",
            "------------------------- Epoch 47 -------------------------\n",
            "Training loss: 2.2801\n",
            "Validation loss: 2.0618\n",
            "\n",
            "------------------------- Epoch 48 -------------------------\n",
            "Training loss: 2.2792\n",
            "Validation loss: 2.0720\n",
            "\n",
            "------------------------- Epoch 49 -------------------------\n",
            "Training loss: 2.2706\n",
            "Validation loss: 2.0745\n",
            "\n",
            "------------------------- Epoch 50 -------------------------\n",
            "Training loss: 2.2685\n",
            "Validation loss: 2.0771\n",
            "\n",
            "------------------------- Epoch 51 -------------------------\n",
            "Training loss: 2.2698\n",
            "Validation loss: 2.0768\n",
            "\n",
            "------------------------- Epoch 52 -------------------------\n",
            "Training loss: 2.2663\n",
            "Validation loss: 2.0500\n",
            "\n",
            "------------------------- Epoch 53 -------------------------\n",
            "Training loss: 2.2637\n",
            "Validation loss: 2.0840\n",
            "\n",
            "------------------------- Epoch 54 -------------------------\n",
            "Training loss: 2.2645\n",
            "Validation loss: 2.0546\n",
            "\n",
            "------------------------- Epoch 55 -------------------------\n",
            "Training loss: 2.2584\n",
            "Validation loss: 2.0655\n",
            "\n",
            "------------------------- Epoch 56 -------------------------\n",
            "Training loss: 2.2636\n",
            "Validation loss: 2.0534\n",
            "\n",
            "------------------------- Epoch 57 -------------------------\n",
            "Training loss: 2.2529\n",
            "Validation loss: 2.0619\n",
            "\n",
            "------------------------- Epoch 58 -------------------------\n",
            "Training loss: 2.2558\n",
            "Validation loss: 2.0547\n",
            "\n",
            "------------------------- Epoch 59 -------------------------\n",
            "Training loss: 2.2504\n",
            "Validation loss: 2.0354\n",
            "\n",
            "------------------------- Epoch 60 -------------------------\n",
            "Training loss: 2.2487\n",
            "Validation loss: 2.0387\n",
            "\n",
            "------------------------- Epoch 61 -------------------------\n",
            "Training loss: 2.2463\n",
            "Validation loss: 2.0448\n",
            "\n",
            "------------------------- Epoch 62 -------------------------\n",
            "Training loss: 2.2472\n",
            "Validation loss: 2.0531\n",
            "\n",
            "------------------------- Epoch 63 -------------------------\n",
            "Training loss: 2.2412\n",
            "Validation loss: 2.0452\n",
            "\n",
            "------------------------- Epoch 64 -------------------------\n",
            "Training loss: 2.2443\n",
            "Validation loss: 2.0576\n",
            "\n",
            "------------------------- Epoch 65 -------------------------\n",
            "Training loss: 2.2399\n",
            "Validation loss: 2.0349\n",
            "\n",
            "------------------------- Epoch 66 -------------------------\n",
            "Training loss: 2.2286\n",
            "Validation loss: 2.0271\n",
            "\n",
            "------------------------- Epoch 67 -------------------------\n",
            "Training loss: 2.2311\n",
            "Validation loss: 2.0392\n",
            "\n",
            "------------------------- Epoch 68 -------------------------\n",
            "Training loss: 2.2337\n",
            "Validation loss: 2.0280\n",
            "\n",
            "------------------------- Epoch 69 -------------------------\n",
            "Training loss: 2.2328\n",
            "Validation loss: 2.0432\n",
            "\n",
            "------------------------- Epoch 70 -------------------------\n",
            "Training loss: 2.2308\n",
            "Validation loss: 2.0401\n",
            "\n",
            "------------------------- Epoch 71 -------------------------\n",
            "Training loss: 2.2275\n",
            "Validation loss: 2.0183\n",
            "\n",
            "------------------------- Epoch 72 -------------------------\n",
            "Training loss: 2.2236\n",
            "Validation loss: 2.0332\n",
            "\n",
            "------------------------- Epoch 73 -------------------------\n",
            "Training loss: 2.2190\n",
            "Validation loss: 2.0239\n",
            "\n",
            "------------------------- Epoch 74 -------------------------\n",
            "Training loss: 2.2251\n",
            "Validation loss: 2.0167\n",
            "\n",
            "------------------------- Epoch 75 -------------------------\n",
            "Training loss: 2.2246\n",
            "Validation loss: 2.0385\n",
            "\n",
            "------------------------- Epoch 76 -------------------------\n",
            "Training loss: 2.2227\n",
            "Validation loss: 2.0274\n",
            "\n",
            "------------------------- Epoch 77 -------------------------\n",
            "Training loss: 2.2168\n",
            "Validation loss: 2.0259\n",
            "\n",
            "------------------------- Epoch 78 -------------------------\n",
            "Training loss: 2.2147\n",
            "Validation loss: 2.0143\n",
            "\n",
            "------------------------- Epoch 79 -------------------------\n",
            "Training loss: 2.2136\n",
            "Validation loss: 2.0209\n",
            "\n",
            "------------------------- Epoch 80 -------------------------\n",
            "Training loss: 2.2119\n",
            "Validation loss: 2.0082\n",
            "\n",
            "------------------------- Epoch 81 -------------------------\n",
            "Training loss: 2.2076\n",
            "Validation loss: 2.0235\n",
            "\n",
            "------------------------- Epoch 82 -------------------------\n",
            "Training loss: 2.2088\n",
            "Validation loss: 2.0139\n",
            "\n",
            "------------------------- Epoch 83 -------------------------\n",
            "Training loss: 2.2065\n",
            "Validation loss: 2.0228\n",
            "\n",
            "------------------------- Epoch 84 -------------------------\n",
            "Training loss: 2.2061\n",
            "Validation loss: 2.0077\n",
            "\n",
            "------------------------- Epoch 85 -------------------------\n",
            "Training loss: 2.2026\n",
            "Validation loss: 2.0082\n",
            "\n",
            "------------------------- Epoch 86 -------------------------\n",
            "Training loss: 2.2025\n",
            "Validation loss: 2.0069\n",
            "\n",
            "------------------------- Epoch 87 -------------------------\n",
            "Training loss: 2.2034\n",
            "Validation loss: 2.0235\n",
            "\n",
            "------------------------- Epoch 88 -------------------------\n",
            "Training loss: 2.2040\n",
            "Validation loss: 2.0002\n",
            "\n",
            "------------------------- Epoch 89 -------------------------\n",
            "Training loss: 2.2000\n",
            "Validation loss: 2.0363\n",
            "\n",
            "------------------------- Epoch 90 -------------------------\n",
            "Training loss: 2.1973\n",
            "Validation loss: 2.0116\n",
            "\n",
            "------------------------- Epoch 91 -------------------------\n",
            "Training loss: 2.2022\n",
            "Validation loss: 2.0134\n",
            "\n",
            "------------------------- Epoch 92 -------------------------\n",
            "Training loss: 2.1968\n",
            "Validation loss: 2.0198\n",
            "\n",
            "------------------------- Epoch 93 -------------------------\n",
            "Training loss: 2.1959\n",
            "Validation loss: 2.0189\n",
            "\n",
            "------------------------- Epoch 94 -------------------------\n",
            "Training loss: 2.1952\n",
            "Validation loss: 2.0114\n",
            "\n",
            "------------------------- Epoch 95 -------------------------\n",
            "Training loss: 2.1917\n",
            "Validation loss: 1.9887\n",
            "\n",
            "------------------------- Epoch 96 -------------------------\n",
            "Training loss: 2.1931\n",
            "Validation loss: 2.0118\n",
            "\n",
            "------------------------- Epoch 97 -------------------------\n",
            "Training loss: 2.1905\n",
            "Validation loss: 2.0011\n",
            "\n",
            "------------------------- Epoch 98 -------------------------\n",
            "Training loss: 2.1862\n",
            "Validation loss: 2.0066\n",
            "\n",
            "------------------------- Epoch 99 -------------------------\n",
            "Training loss: 2.1897\n",
            "Validation loss: 1.9973\n",
            "\n",
            "------------------------- Epoch 100 -------------------------\n",
            "Training loss: 2.1913\n",
            "Validation loss: 2.0078\n",
            "\n",
            "------------------------- Epoch 101 -------------------------\n",
            "Training loss: 2.1888\n",
            "Validation loss: 1.9948\n",
            "\n",
            "------------------------- Epoch 102 -------------------------\n",
            "Training loss: 2.1842\n",
            "Validation loss: 2.0098\n",
            "\n",
            "------------------------- Epoch 103 -------------------------\n",
            "Training loss: 2.1865\n",
            "Validation loss: 1.9903\n",
            "\n",
            "------------------------- Epoch 104 -------------------------\n",
            "Training loss: 2.1832\n",
            "Validation loss: 1.9974\n",
            "\n",
            "------------------------- Epoch 105 -------------------------\n",
            "Training loss: 2.1791\n",
            "Validation loss: 1.9967\n",
            "\n",
            "------------------------- Epoch 106 -------------------------\n",
            "Training loss: 2.1805\n",
            "Validation loss: 1.9981\n",
            "\n",
            "------------------------- Epoch 107 -------------------------\n",
            "Training loss: 2.1795\n",
            "Validation loss: 1.9869\n",
            "\n",
            "------------------------- Epoch 108 -------------------------\n",
            "Training loss: 2.1851\n",
            "Validation loss: 1.9901\n",
            "\n",
            "------------------------- Epoch 109 -------------------------\n",
            "Training loss: 2.1832\n",
            "Validation loss: 1.9965\n",
            "\n",
            "------------------------- Epoch 110 -------------------------\n",
            "Training loss: 2.1804\n",
            "Validation loss: 1.9978\n",
            "\n",
            "------------------------- Epoch 111 -------------------------\n",
            "Training loss: 2.1805\n",
            "Validation loss: 1.9860\n",
            "\n",
            "------------------------- Epoch 112 -------------------------\n",
            "Training loss: 2.1786\n",
            "Validation loss: 1.9928\n",
            "\n",
            "------------------------- Epoch 113 -------------------------\n",
            "Training loss: 2.1788\n",
            "Validation loss: 1.9943\n",
            "\n",
            "------------------------- Epoch 114 -------------------------\n",
            "Training loss: 2.1750\n",
            "Validation loss: 1.9852\n",
            "\n",
            "------------------------- Epoch 115 -------------------------\n",
            "Training loss: 2.1787\n",
            "Validation loss: 1.9845\n",
            "\n",
            "------------------------- Epoch 116 -------------------------\n",
            "Training loss: 2.1750\n",
            "Validation loss: 1.9962\n",
            "\n",
            "------------------------- Epoch 117 -------------------------\n",
            "Training loss: 2.1718\n",
            "Validation loss: 1.9906\n",
            "\n",
            "------------------------- Epoch 118 -------------------------\n",
            "Training loss: 2.1747\n",
            "Validation loss: 1.9873\n",
            "\n",
            "------------------------- Epoch 119 -------------------------\n",
            "Training loss: 2.1726\n",
            "Validation loss: 1.9836\n",
            "\n",
            "------------------------- Epoch 120 -------------------------\n",
            "Training loss: 2.1728\n",
            "Validation loss: 1.9893\n",
            "\n",
            "------------------------- Epoch 121 -------------------------\n",
            "Training loss: 2.1761\n",
            "Validation loss: 1.9848\n",
            "\n",
            "------------------------- Epoch 122 -------------------------\n",
            "Training loss: 2.1737\n",
            "Validation loss: 1.9976\n",
            "\n",
            "------------------------- Epoch 123 -------------------------\n",
            "Training loss: 2.1737\n",
            "Validation loss: 2.0032\n",
            "\n",
            "------------------------- Epoch 124 -------------------------\n",
            "Training loss: 2.1685\n",
            "Validation loss: 1.9765\n",
            "\n",
            "------------------------- Epoch 125 -------------------------\n",
            "Training loss: 2.1680\n",
            "Validation loss: 1.9902\n",
            "\n",
            "------------------------- Epoch 126 -------------------------\n",
            "Training loss: 2.1719\n",
            "Validation loss: 1.9804\n",
            "\n",
            "------------------------- Epoch 127 -------------------------\n",
            "Training loss: 2.1652\n",
            "Validation loss: 2.0304\n",
            "\n",
            "------------------------- Epoch 128 -------------------------\n",
            "Training loss: 2.1701\n",
            "Validation loss: 1.9910\n",
            "\n",
            "------------------------- Epoch 129 -------------------------\n",
            "Training loss: 2.1723\n",
            "Validation loss: 1.9818\n",
            "\n",
            "------------------------- Epoch 130 -------------------------\n",
            "Training loss: 2.1694\n",
            "Validation loss: 1.9971\n",
            "\n",
            "------------------------- Epoch 131 -------------------------\n",
            "Training loss: 2.1697\n",
            "Validation loss: 2.0050\n",
            "\n",
            "------------------------- Epoch 132 -------------------------\n",
            "Training loss: 2.1677\n",
            "Validation loss: 1.9724\n",
            "\n",
            "------------------------- Epoch 133 -------------------------\n",
            "Training loss: 2.1636\n",
            "Validation loss: 1.9918\n",
            "\n",
            "------------------------- Epoch 134 -------------------------\n",
            "Training loss: 2.1628\n",
            "Validation loss: 1.9797\n",
            "\n",
            "------------------------- Epoch 135 -------------------------\n",
            "Training loss: 2.1669\n",
            "Validation loss: 1.9910\n",
            "\n",
            "------------------------- Epoch 136 -------------------------\n",
            "Training loss: 2.1584\n",
            "Validation loss: 1.9738\n",
            "\n",
            "------------------------- Epoch 137 -------------------------\n",
            "Training loss: 2.1594\n",
            "Validation loss: 1.9842\n",
            "\n",
            "------------------------- Epoch 138 -------------------------\n",
            "Training loss: 2.1638\n",
            "Validation loss: 1.9796\n",
            "\n",
            "------------------------- Epoch 139 -------------------------\n",
            "Training loss: 2.1611\n",
            "Validation loss: 1.9742\n",
            "\n",
            "------------------------- Epoch 140 -------------------------\n",
            "Training loss: 2.1617\n",
            "Validation loss: 1.9871\n",
            "\n",
            "------------------------- Epoch 141 -------------------------\n",
            "Training loss: 2.1595\n",
            "Validation loss: 1.9845\n",
            "\n",
            "------------------------- Epoch 142 -------------------------\n",
            "Training loss: 2.1696\n",
            "Validation loss: 1.9841\n",
            "\n",
            "------------------------- Epoch 143 -------------------------\n",
            "Training loss: 2.1550\n",
            "Validation loss: 1.9780\n",
            "\n",
            "------------------------- Epoch 144 -------------------------\n",
            "Training loss: 2.1560\n",
            "Validation loss: 1.9732\n",
            "\n",
            "------------------------- Epoch 145 -------------------------\n",
            "Training loss: 2.1567\n",
            "Validation loss: 1.9673\n",
            "\n",
            "------------------------- Epoch 146 -------------------------\n",
            "Training loss: 2.1621\n",
            "Validation loss: 1.9755\n",
            "\n",
            "------------------------- Epoch 147 -------------------------\n",
            "Training loss: 2.1620\n",
            "Validation loss: 2.0012\n",
            "\n",
            "------------------------- Epoch 148 -------------------------\n",
            "Training loss: 2.1596\n",
            "Validation loss: 1.9748\n",
            "\n",
            "------------------------- Epoch 149 -------------------------\n",
            "Training loss: 2.1562\n",
            "Validation loss: 1.9762\n",
            "\n",
            "------------------------- Epoch 150 -------------------------\n",
            "Training loss: 2.1579\n",
            "Validation loss: 1.9820\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40f805ad-7748-4785-9066-c5500287a4af",
        "outputId": "cf289f39-f46c-427e-d429-9aa6e0fc2186",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(train_loss_list, label = \"Train loss\")\n",
        "plt.plot(validation_loss_list, label = \"Validation loss\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss vs Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "40f805ad-7748-4785-9066-c5500287a4af",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_loop(model, loss_fn, dataloader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    mape = 0\n",
        "    smape = 0\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            X = batch[0].long()\n",
        "            y = batch[1].long()\n",
        "           # X, y = batch[:, 0], batch[:, 1]\n",
        "          #  X, y = torch.tensor(X, dtype=torch.long, device=device), torch.tensor(y, dtype=torch.long, device=device)\n",
        "            X, y = torch.tensor(X).to(device), torch.tensor(y).to(device)\n",
        "            # Now we shift the tgt by one so with the <SOS> we predict the token at pos 1\n",
        "            y_input = y[:,:-1]\n",
        "            y_expected = y[:,1:]\n",
        "            # print(y_expected)\n",
        "            \n",
        "            # Get mask to mask out the next words\n",
        "            sequence_length = y_input.size(1)\n",
        "            tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n",
        "\n",
        "            # Standard training except we pass in y_input and src_mask\n",
        "            pred = model(X, y_input, tgt_mask)\n",
        "\n",
        "            # Permute pred to have batch size first again\n",
        "            pred = pred.permute(1, 2, 0)\n",
        "            # print(\"expected:\",y_expected.shape)\n",
        "            # print(\"pred:\",pred.shape)\n",
        "\n",
        "            loss = loss_fn(pred, y_expected)\n",
        "            total_loss += loss.detach().item()\n",
        "\n",
        "\n",
        "            pred_class = torch.argmax(pred, dim=1)\n",
        "            pred_class = pred_class.reshape(-1)\n",
        "            y_expected = y_expected.reshape(-1)\n",
        "\n",
        "            epoch_mape = torch.abs(100 * (y_expected - pred_class) / (y_expected + 0.01)).sum().data\n",
        "            epoch_smape = torch.abs(200 * (y_expected - pred_class) / (y_expected + pred_class + 0.01)).sum().data\n",
        "\n",
        "            mape += epoch_mape\n",
        "            smape += epoch_smape            \n",
        "\n",
        "            y_pred += pred_class.tolist()\n",
        "            y_true += y_expected.tolist()\n",
        "        \n",
        "    return total_loss / len(dataloader), y_true, y_pred, mape, smape\n",
        "test_loss, y_true, y_pred, mape, smape = test_loop(model, loss_fn, test_loader)\n",
        "\n",
        "mape = mape / len(test_dataset)\n",
        "smape = smape / len(test_dataset)\n",
        "\n",
        "print(\"test_loss\", test_loss)\n",
        "print(\"MAPE \", mape.item())\n",
        "print(\"SMAPE \", smape.item())\n",
        "\n",
        "import sklearn.metrics as metrics\n",
        "mae = metrics.mean_absolute_error(y_true, y_pred) * 8\n",
        "mse = metrics.mean_squared_error(y_true, y_pred) * 8\n",
        "rmse = mse ** (1/2)\n",
        "\n",
        "print(\"MAE: \", mae)\n",
        "print(\"MSE: \", mse)\n",
        "print(\"RMSE: \", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrtBV8hoaYBu",
        "outputId": "0769c60b-fb7a-47af-d2fa-44ef329d8372"
      },
      "id": "KrtBV8hoaYBu",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_loss 1.972378029354981\n",
            "MAPE  21469.8671875\n",
            "SMAPE  307.5322265625\n",
            "MAE:  70.70725178960473\n",
            "MSE:  7104.1618425147835\n",
            "RMSE:  84.28619010558481\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num = 0\n",
        "for i in range(len(y_pred)):\n",
        "  if y_pred[i] == y_true[i]:\n",
        "    num += 1\n",
        "precision = num / len(y_pred)\n",
        "print(\"Precision: \", precision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df1MV0DefnhV",
        "outputId": "1dc39611-d229-49ed-f731-668b32b6ec04"
      },
      "id": "df1MV0DefnhV",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision:  0.40547774665421726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5df24c30-15b0-471a-ac4d-a0975fbc6a7d",
        "outputId": "11bc48eb-a84f-4d47-db5a-61d2f18c51a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def predict(model, input_sequence, max_length=15, SOS_token=150, EOS_token=152):\n",
        "    model.eval()\n",
        "    \n",
        "    y_input = torch.tensor([[SOS_token]], dtype=torch.long, device=device)\n",
        "\n",
        "    num_tokens = len(input_sequence[0])\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        # Get source mask\n",
        "        tgt_mask = model.get_tgt_mask(y_input.size(1)).to(device)\n",
        "        \n",
        "        pred = model(input_sequence, y_input, tgt_mask)\n",
        "        \n",
        "        next_item = pred.topk(1)[1].view(-1)[-1].item() # num with highest probability\n",
        "        next_item = torch.tensor([[next_item]], device=device)\n",
        "\n",
        "        # Concatenate previous input with predicted best word\n",
        "        y_input = torch.cat((y_input, next_item), dim=1)\n",
        "\n",
        "        # Stop if model predicts end of sentence\n",
        "        if next_item.view(-1).item() == EOS_token:\n",
        "            break\n",
        "\n",
        "    return y_input.view(-1).tolist()\n",
        "  \n",
        "  \n",
        "# Here we test some examples to observe how the model predicts\n",
        "examples = []\n",
        "m = 0\n",
        "for batch in train_dataloader:\n",
        "  X = batch[0].long()\n",
        "  y = batch[1].long()\n",
        "  #X, y = torch.tensor(X).to(device), torch.tensor(y).to(device)\n",
        "  print(X[0])\n",
        "  m = m + 1\n",
        "  if m > 0:\n",
        "    break\n",
        "\n",
        "examples = [X[0],X[1],X[2],X[3]]\n",
        "print(examples)\n",
        "print(y[0])\n",
        "print(y[1])\n",
        "print(y[2])\n",
        "print(y[3])\n",
        "\n",
        "examples = [\n",
        "    #torch.tensor([train_dataloader[1]], dtype=torch.long, device=device),\n",
        "    torch.tensor([[150,   5,  10,   4,   0,   2,  10,   2,   9,   2,   9,   3,   0,   3, 9,   1,   7,   2,   7,   4,   0,   3,   2,   2,   7, 152]], dtype=torch.long, device=device),\n",
        "    torch.tensor([[150,  30,  81,  72,   0,  18,  38,   7,  66,  36,  79,  70,   0,  24,\n",
        "         31,   6,  71,  50,  80,  83,   0,  14,  28,   6,  79, 152]], dtype=torch.long, device=device),\n",
        "    torch.tensor([[150,   9,  15,  10,   0,   1,   3,   2,  18,   5,  13,   7,   0,   1,\n",
        "          8,   0,  15,   9,  11,   8,   0,   1,   5,   0,   9, 152]], dtype=torch.long, device=device),\n",
        "    torch.tensor([[150,  42,  31,  38,   0,  13,  60,  16,  31,  35,  34,  27,   0,  20,\n",
        "         43,  12,  32,  47,  34,  37,   0,  16,  58,  14,  43, 152]], dtype=torch.long, device=device),\n",
        "   # torch.tensor([[150, 13,  7, 13,  0,  4, 12,  2,  9, 100]], dtype=torch.long, device=device)\n",
        "    # torch.tensor([[2, 0, 0, 0, 4, 0, 3]], dtype=torch.long, device=device),\n",
        "    # torch.tensor([[2, 1, 1, 1, 1, 1, 3]], dtype=torch.long, device=device),\n",
        "    # torch.tensor([[2, 1, 0, 1, 6, 1, 3]], dtype=torch.long, device=device),\n",
        "    # torch.tensor([[2, 0, 1, 0, 1, 0, 3]], dtype=torch.long, device=device),\n",
        "    # torch.tensor([[2, 0, 1, 0, 7, 0, 3]], dtype=torch.long, device=device),\n",
        "    # torch.tensor([[2, 0, 1, 0, 1, 1, 3]], dtype=torch.long, device=device)\n",
        "]\n",
        "\n",
        "for idx, example in enumerate(examples):\n",
        "    result = predict(model, example)\n",
        "    print(f\"Example {idx}\")\n",
        "    print(f\"Input: {example.view(-1).tolist()[1:-1]}\")\n",
        "    print(f\"Continuation: {result[1:-1]}\")\n",
        "    print()"
      ],
      "id": "5df24c30-15b0-471a-ac4d-a0975fbc6a7d",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([150,   9,  40,  23,   0,   2,  32,   8,  34,   8,  34,  20,   0,   1,\n",
            "         25,   5,  33,  10,  35,  18,   0,   1,  20,   6,  31, 152])\n",
            "[tensor([150,   9,  40,  23,   0,   2,  32,   8,  34,   8,  34,  20,   0,   1,\n",
            "         25,   5,  33,  10,  35,  18,   0,   1,  20,   6,  31, 152]), tensor([150,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 152]), tensor([150,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 152]), tensor([150,   5,   7,   4,   0,   2,   5,   0,   9,   2,   7,   5,   0,   2,\n",
            "          2,   1,   3,   3,   3,   4,   0,   3,   5,   0,   3, 152])]\n",
            "tensor([150,   7,  30,  31,   0,   1,  24,  10,  35, 152])\n",
            "tensor([150,   0,   0,   0,   0,   0,   0,   0,   0, 152])\n",
            "tensor([150,   0,   0,   0,   0,   0,   0,   0,   0, 152])\n",
            "tensor([150,   5,   2,   3,   0,   1,   1,   1,   5, 152])\n",
            "Example 0\n",
            "Input: [5, 10, 4, 0, 2, 10, 2, 9, 2, 9, 3, 0, 3, 9, 1, 7, 2, 7, 4, 0, 3, 2, 2, 7]\n",
            "Continuation: [5, 8, 5, 0, 2, 5, 0, 5]\n",
            "\n",
            "Example 1\n",
            "Input: [30, 81, 72, 0, 18, 38, 7, 66, 36, 79, 70, 0, 24, 31, 6, 71, 50, 80, 83, 0, 14, 28, 6, 79]\n",
            "Continuation: [31, 68, 68, 0, 16, 31, 6, 70]\n",
            "\n",
            "Example 2\n",
            "Input: [9, 15, 10, 0, 1, 3, 2, 18, 5, 13, 7, 0, 1, 8, 0, 15, 9, 11, 8, 0, 1, 5, 0, 9]\n",
            "Continuation: [6, 12, 10, 0, 2, 8, 1, 16]\n",
            "\n",
            "Example 3\n",
            "Input: [42, 31, 38, 0, 13, 60, 16, 31, 35, 34, 27, 0, 20, 43, 12, 32, 47, 34, 37, 0, 16, 58, 14, 43]\n",
            "Continuation: [42, 26, 33, 0, 16, 46, 17, 33]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBpKjFT93Lpr"
      },
      "source": [
        ""
      ],
      "id": "RBpKjFT93Lpr",
      "execution_count": null,
      "outputs": []
    }
  ]
}